@ARTICLE{10681400,
  author={Lelis, Claudio A. S. and Roncal, Julio J. and Silveira, Leonardo and De Aquino, Roberto Douglas G. and Marcondes, Cesar A. C. and Marques, Johnny and Loubach, Denis S. and Verri, Filipe A. N. and Curtis, Vitor V. and De Souza, Diego G.},
  journal={IEEE Access}, 
  title={Drone-Based AI System for Wildfire Monitoring and Risk Prediction}, 
  year={2024},
  volume={12},
  number={},
  pages={139865-139882},
  abstract={Wildfires pose a significant threat to ecosystems, human lives, and infrastructure worldwide. Traditional wildfire detection and risk assessment methods often suffer from limitations such as delayed detection and low confidence in certain regions. In this paper, we propose a novel computational system based on Machine Learning for wildfire risk assessment using data collected by drones. The system can integrate various sensors to capture spatiotemporal data on environmental factors such as temperature, humidity, and vegetation. By leveraging high-resolution data collected through autonomous drone missions, our system enhances wildfire risk estimation and enables proactive mission planning. Although the system is mainly designed to address wildfire monitoring using drone-collected data, it can be easily adapted to other environmental monitoring applications and other sources of data. We demonstrate the effectiveness of our approach through a comprehensive evaluation and validation process in both simulated and real-world environments. Our work contributes to advancing wildfire monitoring capabilities, improving early detection, and mitigating the impact of wildfires on communities and the environment.},
  keywords={Wildfires;Predictive models;Sensors;Normalized difference vegetation index;Measurement;Drones;Artificial intelligence;Environmental monitoring;Machine learning;Risk management;Spatiotemporal phenomena;Aerial drones;artificial intelligence;environmental monitoring;machine learning;risk assessment;spatiotemporal data;wildfire detection;wildfire risk estimation},
  doi={10.1109/ACCESS.2024.3462436},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10677778,
  author={Devi, Kavuluri Leela Sai Rasagna and Kumar, Garnepudi Narasimha and Narayana, Potturi Ashok and Ramana, Kakani Venkata and Amarendra, K and Gullipalli, Tirupathi Rao},
  booktitle={2024 8th International Conference on Inventive Systems and Control (ICISC)}, 
  title={Forest Fire Prediction and Management using AI (Artificial Intelligence), ML (Machine Learning) and Deep Learning Techniques}, 
  year={2024},
  volume={},
  number={},
  pages={324-327},
  abstract={Forest fires pose significant threats to public safety and the environment, releasing hazardous pollutants and spreading rapidly through vegetated areas. Early detection is critical to prevent forest fires from becoming catastrophic, but the dynamic nature of weather conditions complicates this process. This study addresses the challenge by employing advanced Deep Learning (DL) techniques, utilizing algorithms such as Support Vector Machines (SVM), Logistic Regression, and Convolutional Neural Networks (CNN) to analyze images captured by satellites, drones, and webcams. Developing a neural model involves constructing, training, and fine-tuning sophisticated algorithms, optimizing accuracy by adjusting parameters such as dense layers and hidden layers. Data preprocessing techniques, including data augmentation, are used to enhance the input and improve model performance. The integration of new technologies and approaches, such as deep learning and data augmentation, aims to mitigate the effects of wildfires and protect both human lives and the environment. The ultimate goal of this research study is to enhance early detection systems and reduce response times, thereby minimizing the detrimental impact of forest fires on ecosystems and communities.},
  keywords={Climate change;Deep learning;Neural networks;Predictive models;Convolutional neural networks;Forests;Fires;Environmental factors;Prevention and mitigation;Public security;Artificial intelligence;Machine learning;Deep learning;Pollution measurement;Support vector machines;Drones;Satellite images;Detection algorithms;Deep Learning (DL);Neural Models;Forest Fires;Climate change;prediction;early detection;CNN},
  doi={10.1109/ICISC62624.2024.00062},
  ISSN={},
  month={July},}@INPROCEEDINGS{10053123,
  author={Gupta, Vaasu and Roy, Sutirtha and Jaiswal, Vaibhav and Bhardwaj, Kartik and Rana, Prashant Singh},
  booktitle={2022 Seventh International Conference on Parallel, Distributed and Grid Computing (PDGC)}, 
  title={Drone Assisted Deep Learning based Wildfire Detection System}, 
  year={2022},
  volume={},
  number={},
  pages={162-166},
  abstract={Wildfires are one of the major threats to forest sustainability. Therefore, there is an urgent need for an early prevention system for wildfires. The flight controller comprises a Node Micro-Controller Unit board and is controlled by an ESP8266-based Wireless setup. To address the problem of wildfire monitoring in forests, this paper proposes a wildfire monitoring system based on drones and deep learning techniques. In the present study, after pre-processing the images collected from a drone camera, deep learning models are used to classify them as containing fire or non-fire. Among the approaches discussed, the customized Inception model trained over the combined data-set from six different sources outperforms the previously presented works, achieving an overall validation accuracy of 96.04% and performing well on fire-like images and from bright day to dim light images also.},
  keywords={Deep learning;Wireless communication;Surveillance;Fires;Forestry;Grid computing;Data models;Drones;Deep Learning;Internet of Things (IoT);Unmanned Aerial Vehicle (UAV)},
  doi={10.1109/PDGC56933.2022.10053123},
  ISSN={2573-3079},
  month={Nov},}@INPROCEEDINGS{10679999,
  author={Zhou, Calvin},
  booktitle={2024 International Conference on Advanced Robotics and Intelligent Systems (ARIS)}, 
  title={A2D2: AI-Driven Autonomous Drone-Based Detection Network for Wildfires}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={Unmanned aerial vehicles (UAVs) or drones have promising advantages in wildfire detection, outperforming conventional systems in mobility and versatility. However, current drone operations such as path planning, maneuver control, and data analysis require significant manual work, restricting drone systems' efficiency and effectiveness. To reduce human efforts while improving performance, this paper proposes A2D2, an AI-driven Autonomous Drone-based Detection network, aiming to fully automate the drone operational process for wildfire detection. The proposed system is driven by AI models and automated solutions, including a deep computer vision (DCV) model for wildfire detection, a coverage path planning (CPP) method managing patrol navigation, and a deep reinforcement learning (DRL) model controlling drone's path towards the detected wildfires for inspection. This system programmatically manages the model functions in different stages to ensure autonomous operations with minimal human intervention. This paper describes the design, implementation, and experimental tests of the proposed system, including mathematical analysis and algorithms. The approaches and solutions introduced in this research contribute to the advancements of integrating AI technologies into autonomous drone systems and applications.},
  keywords={Wildfires;Data analysis;Navigation;Computational modeling;Mathematical analysis;Inspection;Deep reinforcement learning;unmanned aerial vehicle;autonomous drone system;wildfire detection;deep computer vision;coverage path planning;deep reinforcement learning},
  doi={10.1109/ARIS62416.2024.10679999},
  ISSN={2572-6919},
  month={Aug},}@INPROCEEDINGS{9404629,
  author={Chaudhary, Sunil Kumar and Yadav, Archana and Sharma, Bipul and Rouf, Muntaha and Gupta, Vishal},
  booktitle={2021 International Conference on Advance Computing and Innovative Technologies in Engineering (ICACITE)}, 
  title={RF Controlled Solar Based Robotic Drone}, 
  year={2021},
  volume={},
  number={},
  pages={427-431},
  abstract={In this paper, we present the recent research in the development of AL drones by using an algorithm of deep learning (A subset of machine learning algorithms) and computer vision (CV) based on a drone camera, the study explores the potential use of drones not only in searching the victim person, animals, important properties during natural calamities like flood, volcanoes eruption, forest fire, cyclones, and earthquake, etc. but also it insights into much useful information to collect to ensure the future safety by using a machine learning algorithm. Preparing for and responding to disasters is a major logistical challenge. "Actionable Data" is the next powerful approach and reliable to the Al drones. As we know that drones often generate a huge amount of data - sometimes it produces a large amount of data that we can't handle at a time. Unmanned Aerial Vehicles (UAVs) are the only possible approach that can add value to our AI-based drone without putting any additional efforts to make UAVs more frequent automation. During search and rescue operations, UAVs played a crucial role over humans. As we know that UAVs can be sent to any desired location without any prior knowledge about the exact conditions in the target area. In this paper, we worked to reduce the number of factors that cause hindrance to the effective deployment of UAVs and increasing the duration of flight duration for the rescue operation. We also use the first Indian microprocessor Shakti class c which is installed in the board Artix-7.},
  keywords={Deep learning;Radio frequency;Location awareness;Machine learning algorithms;Microprocessors;Neural networks;Volcanoes;UAVs;Computer vision;Rescue drone;Artix-7;Shakti Processor},
  doi={10.1109/ICACITE51222.2021.9404629},
  ISSN={},
  month={March},}@INPROCEEDINGS{10430519,
  author={Pandey, Ankit and Ahmad, Naeem and Saha, Dibakar},
  booktitle={2023 OITS International Conference on Information Technology (OCIT)}, 
  title={Detection of ground holes using Deep Learning for Surveillance}, 
  year={2023},
  volume={},
  number={},
  pages={220-225},
  abstract={For border area security and surveillance, maintaining vigilance and detecting potential threats is of utmost importance. While surveillance drones have proven effective in enhancing border area monitoring, there are instances where ground pits can raise suspicion. Ground pits, often excavated or dug into the earth, can serve as hidden locations for various illicit activities. The inconspicuous nature of ground pits makes intruders attractive to criminals attempting to evade detection. Deep learning has shown promising potential in automating object detection through visual data. Integrating the deep learning model into drones would provide a more comprehensive and robust surveillance system. In this paper, an image dataset of ground pits referred to as Ground Pit Image Dataset (GPID) is developed to train and test YOLO. This dataset contains 300 images of different ground pits on various surfaces, captured through drones and annotated using online tools. YOLO has provided more than 90% accuracy, which is better than other deep-learning models.},
  keywords={Deep learning;YOLO;Visualization;Surveillance;Excavation;Security;Drones;Computer Vision;Ground Pit Image Dataset (GPID);YOLO;Deep Learning;CNN},
  doi={10.1109/OCIT59427.2023.10430519},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{10621501,
  author={Mukkamala, Ravi and Olariu, Stephan and Aljohani, Meshari and Sunkara, Mohan and Aldabagh, Hind},
  booktitle={2024 20th International Conference on Distributed Computing in Smart Systems and the Internet of Things (DCOSS-IoT)}, 
  title={An Adaptive Drone-based Multigenerational Sensor System for Monitoring Large Ecosystems}, 
  year={2024},
  volume={},
  number={},
  pages={361-368},
  abstract={With the increase in the use of sensors and drones to monitor soil and crop conditions in vast agricultural lands as well as for situational-monitoring of natural disasters such as forest fires and increasing sea levels, there is a need for systems that can support long-term monitoring with minimal cost. In this paper, we propose a novel architecture that combines sensor, drone, blockchain, and machine learning technologies to support a long-term monitoring system for vast areas of land. Long-term monitoring is achieved by employing multigenerational sensors that have been deployed at the start but are woken up in stages as and when needed to replace or reinforce existing sensors. A swarm of drones periodically scans the landscape to identify areas that need immediate attention (e.g., dry soil, pests or insects, humidity, temperature, etc.). Drones store and process the data using onboard units and make real-time decisions regarding changing path plans or changing scanning frequencies. Optionally, data is sent to the base station that fuses the information from multiple drones in the swarm, and inputs the fused data to a machine-learning model that recommends the needed actions. The actions may include obtaining additional data, awakening more sensors, actions to handle any situation by signaling for external actions such as cloud seeding, controlled chemical spraying from a drone, etc., in agricultural applications. Using simulated scenarios, we have employed three prediction algorithms—the Prophet model, CNN, and LSTM—to determine the effectiveness of these algorithms in predicting sensors values in the simulated scenarios. The proposed architecture is scalable, supports long-term monitoring, and is effective in predicting future conditions to enable preemptive actions.},
  keywords={Temperature sensors;Chemical sensors;Machine learning;Computer architecture;Soil;Prediction algorithms;Sensor systems;Agriculture;Sensors;Drones;UAVs;Machine Learning;Smart contract;Blockchain;Blackbox},
  doi={10.1109/DCOSS-IoT61029.2024.00061},
  ISSN={2325-2944},
  month={April},}@INPROCEEDINGS{10620877,
  author={Briley, Austin Alexander and Afghah, Fatemeh},
  booktitle={IEEE INFOCOM 2024 - IEEE Conference on Computer Communications Workshops (INFOCOM WKSHPS)}, 
  title={Hardware Acceleration for Real-Time Wildfire Detection Onboard Drone Networks}, 
  year={2024},
  volume={},
  number={},
  pages={01-06},
  abstract={Early wildfire detection in remote and forest areas is crucial for minimizing devastation and preserving ecosystems. Autonomous drones offer agile access to remote, challenging terrains, equipped with advanced imaging technology that deliv-ers both high-temporal and detailed spatial resolution, making them valuable assets in the early detection and monitoring of wildfires. However, the limited computation and battery resources of Unmanned Aerial Vehicles (UAVs) pose significant challenges in implementing robust and efficient image classification models. Current works in this domain often operate offline, emphasizing the need for solutions that can perform inference in real time, given the constraints of UAVs. To address these challenges, this paper aims to develop a real-time image classification and fire segmentation model. It presents a comprehensive investigation into hardware acceleration using the Jetson Nano P3450 and the implications of TensorRT, NVIDIA's high-performance deep-learning inference library, on fire classification accuracy and speed. The study includes implementations of Quantization Aware Training (QAT), Automatic Mixed Precision (AMP), and post-training mechanisms, comparing them against the latest baselines for fire segmentation and classification. All experiments utilize the FLAME dataset - an image dataset collected by low-altitude drones during a prescribed forest fire, focusing on key performance metrics such as latency, Mean Pixel Accuracy (MPA), Mean Intersection over Union (MIOU), Frames Per Second (FPS), batch size, throughput, and memory utilization (Active Memory, Allocator State). This work contributes to the ongoing efforts to enable real-time, on-board wildfire detection capabilities for UAVs, addressing speed and the computational and energy constraints of these crucial monitoring systems. The results show a 13% increase in classification speed compared to similar models without hardware optimization. Comparatively, loss and accuracy are within 1.225% of original values. The provided source code and additional information are available on the IS-WIN Fire Classification Research page.11https://github.com/Austin-TheTrueShinobi/IS-WiN-Research.},
  keywords={Image segmentation;Wildfires;Accuracy;Quantization (signal);Biological system modeling;Computational modeling;Real-time systems;Wildfire;UAV networks;Classification;Infer-ence;Hardware Acceleration;Segmentation},
  doi={10.1109/INFOCOMWKSHPS61880.2024.10620877},
  ISSN={2833-0587},
  month={May},}@INPROCEEDINGS{8900436,
  author={Allauddin, Md. Saif and Kiran, G. Sai and Kiran, GSS. Raj and Srinivas, G and Mouli, G Uma Ratna and Prasad, P Vishnu},
  booktitle={IGARSS 2019 - 2019 IEEE International Geoscience and Remote Sensing Symposium}, 
  title={Development of a Surveillance System for Forest Fire Detection and Monitoring using Drones}, 
  year={2019},
  volume={},
  number={},
  pages={9361-9363},
  abstract={The purpose of the project is to detect a forest fire in its earliest stage possible by implementing a surveillance system which primarily consists of drones. The nearest authority will be notified shortly about the location of the fire.},
  keywords={Drone;fire;machine learning;Deep Learning;Surveillance},
  doi={10.1109/IGARSS.2019.8900436},
  ISSN={2153-7003},
  month={July},}@INPROCEEDINGS{10564291,
  author={Davis, Mason and Shekaramiz, Mohammad},
  booktitle={2024 Intermountain Engineering, Technology and Computing (IETC)}, 
  title={Image Classification of Forest Fires Using Machine and Deep Learning}, 
  year={2024},
  volume={},
  number={},
  pages={270-275},
  abstract={With the increasing threat presented by climate change, forest fires are becoming more destructive and frequent. These catastrophes present immense danger to our forest ecosystems, infrastructure, and overall health. To dispatch resources in a timely manner, quick and accurate identification of these fires is crucial. Here, machine and deep learning can be leveraged as a solution. In this research, we investigate the classification abilities of Support Vector Machines (SVM), Xception, ResNetSO, and MobileViT. In addition, two transfer learning approaches making use of Xception and ResNet50 as the backbone networks are explored. The popular DeepFire dataset is utilized for the training and comparison of model performance. After tuning each architecture, our results indicate the transfer learning approach with Xception as the backbone provides the highest accuracy obtaining 99.211%.},
  keywords={Deep learning;Support vector machines;Training;Climate change;Accuracy;Computational modeling;Transfer learning;Deep learning;Forest fire;Transfer learning;SVM;ResNet;Xception;MobileViT},
  doi={10.1109/IETC61393.2024.10564291},
  ISSN={},
  month={May},}@INPROCEEDINGS{10048878,
  author={Meena, Utkarsh and Munjal, Geetika and Sachdeva, Sanya and Garg, Pranjul and Dagar, Daksh and Gangal, Anushka},
  booktitle={2023 13th International Conference on Cloud Computing, Data Science & Engineering (Confluence)}, 
  title={RCNN Architecture for Forest Fire Detection}, 
  year={2023},
  volume={},
  number={},
  pages={699-704},
  abstract={Deep learning field is helping world by providing solution to various disasters, one such disaster is forest fire In our current work we are using deep learning algorithm Region-Based Convolutional Neural Network(RCNN) to predict forest fires in images. The purpose of using such system is to construct a model for early wild fire detection and further helping in damage control caused by such instances Forest fires can be detected through various ways like sensor detection and geological data analysis in real time. But one of the best ways to detect fire is using image classification in which Deep learning is the most effective solution. By using deep learning techniques these response systems can be added or configured with drones so that images can be clicked easily form the sky on regular basis and detect smoke in dense forest and alert the authorities so that action can be taken as fast as possible. In our model we focused on fire detection using CNN and RCNN method and results are achieved in terms of accuracy. It is observed that RCNN has achieved an accuracy of 0.97 as compared to 0.92 accuracy of CNN at 20 epochs. Thus such deep learning based model can be a solution for handling disastrous situations.},
  keywords={Deep learning;Geology;Fires;Forestry;Prediction algorithms;Real-time systems;Data models;RCNN;Deep learning;Forest Fire},
  doi={10.1109/Confluence56041.2023.10048878},
  ISSN={},
  month={Jan},}@INPROCEEDINGS{9442053,
  author={Lohit, Gandham Venkata Sai},
  booktitle={2021 7th International Conference on Advanced Computing and Communication Systems (ICACCS)}, 
  title={Reforestation Using Drones and Deep Learning Techniques}, 
  year={2021},
  volume={1},
  number={},
  pages={847-852},
  abstract={Deforestation in the recent times is proving to be a major threat towards destabilizing the earth natural cycles. Due to reduction of trees the earth undergoes the phenomenon of `Green House Effect', wherein the greenhouse gases majorly carbon dioxide, methane, nitrogen dioxide and chlorofloro carbons, traps the sun's light (IR range) in the atmosphere more than required to maintain an equilibrium, which cause the earth to heat up, proving fatal for life forms on earth. When trees are cut down the carbon dioxide which they store to maintain an equilibrium will now be released in to the earth atmosphere, which adds to the cause. The main contributors towards the greenhouse gases are the agriculture and forestry activities. These include forest fires, tree chopping for agriculture and husbandry, urban sprawling and logging of trees. Due, to these activities the mother nature is slowly losing its capacity to reforest and existing tools and nursey supply chains are largely inadequate to fill the gap, and this is the challenge we would like to address using our project “Reforestation using drone and deep learning”. We study about how drones and be used for reforestation and making a working prototype of the same. Using drone reforestation, we can tackle a multitude of problems like, it is 9 times faster than other human planting systems, staying airborne, allows efficient and quick travelling, saving time and coverage if more area in less time and more efficiency. We look into the future scope wherein we also devise a method where deep learning techniques can be used efficiently for tracking deforested land by a drone and sowing the required seeds at that exact location by hovering to that point or dropping the seed airborne.},
  keywords={Earth;Deep learning;Greenhouse effect;Terrestrial atmosphere;Vegetation;Carbon dioxide;Forestry;Deforestation;Greenhouse effect;Drones;Reforestation;MobileNet Architecture},
  doi={10.1109/ICACCS51430.2021.9442053},
  ISSN={2575-7288},
  month={March},}@INPROCEEDINGS{10691280,
  author={Radzi, Faiqah Nur Adlina Mohd and Zulkifley, Mohd Asyraf and Kadim, Zulaikha},
  booktitle={2024 IEEE 15th Control and System Graduate Research Colloquium (ICSGRC)}, 
  title={A Concise Review of Artificial Intelligence Methods for Forest-Fire Monitoring Systems}, 
  year={2024},
  volume={},
  number={},
  pages={1-5},
  abstract={Forest fire is a frequently occurring natural disaster that happens all over the world, especially in tropical regions. There are several types of forest fires that include ground, surface, and crown, which can be monitored by using ground cameras, drones, and satellite imaging. Forest fires bring negative impacts not just to the environment, but also to the local economies. Thus, it is important to monitor and identify forest fires while the fire spit is relatively small using several intelligent technologies. Generally, the traditional way of monitoring forest fire is by using man-powered patrols, watchtowers, and remote sensing devices. The traditional way not only lacks in terms of accuracy, but this method also requires more manpower to maintain the monitoring system. Not to mention that the previously mentioned method is also more time-consuming before the fire spot can be detected. Therefore, artificial intelligence methods have been widely explored in order to enhance the performance of forest fire monitoring systems. High accuracy and fast response in detecting forest fires can lead to saving a lot of our precious forest resources. This article aims to review the artificial intelligence-based methods used in forest fire monitoring systems. There are two key comparison factors have been identified, which are then grouped into conventional machine learning and deep learning methods. Three machine learning methodologies, which are classification, detection, and segmentation have been used to identify the forest fire spots. An analysis has been performed in terms of model architecture, data type, and suitability of the methods. Three subsections have been constructed in the context of forest fire monitoring, which are 1) introduction, 2) methodology that is divided into two categories, conventional machine learning, and deep learning, and 3) conclusion and future works.},
  keywords={Deep learning;Analytical models;Accuracy;Satellites;Reviews;Scalability;Forestry;Artificial Intelligence;Conventional Machine Learning;Deep Learning;Forest Fire Monitoring},
  doi={10.1109/ICSGRC62081.2024.10691280},
  ISSN={2833-1028},
  month={Aug},}@INPROCEEDINGS{8518581,
  author={Thomazella, R. and Castanho, J. E. and Dotto, F.R.L. and Júnior, O.P. Rodrigues and Rosa, G.H. and Marana, A.N. and Papa, J.P.},
  booktitle={IGARSS 2018 - 2018 IEEE International Geoscience and Remote Sensing Symposium}, 
  title={Environmental Monitoring Using Drone Images and Convolutional Neural Networks}, 
  year={2018},
  volume={},
  number={},
  pages={8941-8944},
  abstract={Recently, drone images have been used in a number of applications, mainly for pollution control and surveillance purposes. In this paper, we introduce the well-known Convolutional Neural Networks in the context of environmental monitoring using drone images, and we show their robustness in real-world images obtained from uncontrolled scenarios. We consider a transfer learning-based approach and compare two neural models, i.e., VGG16 and VGG19, to distinguish four classes: “water”, “deforesting area”, “forest”, and “buildings”. The results are analyzed by experts in the field and considered pretty much reasonable.},
  keywords={Drones;Training;Buildings;Forestry;Monitoring;Neural networks;Sports;Land-use classification;Drones;Convolutional Neural Networks},
  doi={10.1109/IGARSS.2018.8518581},
  ISSN={2153-7003},
  month={July},}@INPROCEEDINGS{9946633,
  author={Sood, Kanika and Tran, Peter and Mahto, Rakeshkumar},
  booktitle={2022 IEEE 13th Annual Information Technology, Electronics and Mobile Communication Conference (IEMCON)}, 
  title={Data Normalization Technique for Energy Efficient Drones: An Ensemble Learning Approach}, 
  year={2022},
  volume={},
  number={},
  pages={0411-0416},
  abstract={Frequent wildfires in the western part of the United States are affecting the local economy, flora and fauna, air quality, and health of the local community. Over the years, various techniques have been utilized for the early detection of wildfires, that include satellites, lookout towers, and drones. Among various techniques, drones are gaining popularity due to recent advancements in drone technology, multi-role adaptability, and lower cost of operation. However, to be effective during disaster management and monitoring, the endurance and longevity of the drone's flight time are essential. A transistor-embedded photovoltaics (PV) panel-powered drone can enable such essential qualities required in the drone. Such a power source requires an efficient algorithm for switching the configuration of the PV panel for them to be effective during different lighting and operating conditions. Machine learning classification techniques such as Random Forest for activating the algorithm have shown effectiveness in detecting the presence of shade. However, with a larger number of properties for training, supervised ML classification can result in increased memory usage and, in some cases, lower accuracy. In this paper, we propose a novel normalization technique to reduce the number of properties required to train a machine learning model. After applying the normalization technique, We observed the performance of the Random Forest classification model increased to 90.1 % for shade detection in the PV module, along with a 7.535 % reduction in memory usage.},
  keywords={Photovoltaic systems;Training;Machine learning algorithms;Satellites;Poles and towers;Fires;Switches;photovoltaics (PV);machine learning;random forest;power-management;drones},
  doi={10.1109/IEMCON56893.2022.9946633},
  ISSN={2644-3163},
  month={Oct},}@INPROCEEDINGS{9162586,
  author={Rashid, Md Tahmid and Zhang, Daniel and Wang, Dong},
  booktitle={IEEE INFOCOM 2020 - IEEE Conference on Computer Communications Workshops (INFOCOM WKSHPS)}, 
  title={Poster Abstract: A Computational Model-Driven Hybrid Social Media and Drone-Based Wildfire Monitoring Framework}, 
  year={2020},
  volume={},
  number={},
  pages={1362-1363},
  abstract={While computational model-based wildfire prediction provides reasonable accuracy in predicting wildfire behaviour, they are often limited due to lack of constant availability of real-time data. By contrast, social sensing is an emerging sensing paradigm able to obtain early signs of forest fires from online social media users (e.g. smoke in nearby cities), but suffers from inconsistent reliability due to unreliable social signals. Meanwhile, UAV-based physical sensing utilizes onboard physical sensors to perform reliable wildfire sensing, but requires manual efforts to be narrowed down to fire infested regions. In this poster, we present CompDrone, a novel computational model-driven social media and drone-based wildfire monitoring framework that exploits the collective strengths of computational modeling, social sensing, and drone-based physical sensing for reliable wildfire monitoring. In particular, the CompDrone framework leverages techniques from cellular automata, constrained optimization, and bottom-up game theory to solve a few technical challenges involved in monitoring wildfires. The evaluation results using a real-world forest fire monitoring application show that CompDrone outperforms the state-of-the-art monitoring schemes.},
  keywords={Sensors;Drones;Computational modeling;Monitoring;Data models;Social network services;Reliability},
  doi={10.1109/INFOCOMWKSHPS50562.2020.9162586},
  ISSN={},
  month={July},}@INPROCEEDINGS{10617076,
  author={Bisht, Rajendra Singh and Al-Farouni, Mohammed and Dhabi, Mr.Dharmesh and Abdullah, Falah Hassan and Abdtawfeeq, Tareq Hafdhi and Jaafar, Abdul Hassan Majli and Mezaal, Ali Abdulkareem},
  booktitle={2024 4th International Conference on Advance Computing and Innovative Technologies in Engineering (ICACITE)}, 
  title={Utilizing AI and IoT Communication for SMART Environment System in Intrusion and Fire Incident Scenarios}, 
  year={2024},
  volume={},
  number={},
  pages={1047-1050},
  abstract={One of the most common and damaging natural catastrophes, wildfires seriously harm the environment, society, and economy. It is possible to significantly improve early forest fire prediction, detection, and suppression by utilising transfer learning methods and contemporary machine learning tools. The proposed method uses a fleet of drones equipped with advanced decision-making tools and capable of processing high-definition photos to detect forest fires early on. Particle swarm optimisation techniques are used to quickly contain the fire at its beginning thanks to the system’s creation of firefighting plans and fast notification of the fire and rescue departments. In addition, the drone network actively tracks forest fires in real time and helps put them out. Utilising deep learning models like ResNet, VGGNet, MobileNet, AlexNet, and GoogLeNet, the system demonstrates an impressive level of accuracy in identifying probable fire threats. The suggested GoogLeNet-TL approach outperforms cutting-edge deep learning models in terms of accuracy and F1 score, as evidenced by experimental findings.},
  keywords={Deep learning;Accuracy;Wildfires;Biological system modeling;Transfer learning;Forestry;Real-time systems;Intelligent Security System;Unmanned Aerial Vehicle (UAV);Artificial Intelligence (AI;Fire Accident Detection;Illegal Incursion Monitoring},
  doi={10.1109/ICACITE60783.2024.10617076},
  ISSN={},
  month={May},}@INPROCEEDINGS{10307785,
  author={Roy, Rita and Mohanta, Bhabendu Kumar and Rao, G Appa and Sujatha, Pilli},
  booktitle={2023 14th International Conference on Computing Communication and Networking Technologies (ICCCNT)}, 
  title={Machine Learning Techniques for Detection of Forest Fire}, 
  year={2023},
  volume={},
  number={},
  pages={1-5},
  abstract={Forests are an essential natural resource for humanity because they provide a variety of direct and indirect advantages. It is essential to investigate the automatic detection of forest fires to prevent catastrophes. First, to address the issue of unequal distribution and a lack of samples, high-quality samples of forest fires were produced using General Advanced Networks, or GAN. Second, the forest fire area picture was predicted using an Adaboost classifier based on the properties of HOG (Histogram of Oriented Gradients), and the fire area was recognized secondarily using convolutional neural networks (CNN) and other methods: support vector machines, or SVMs. We want to automatically identify forest fires using deep learning (DL) based on the dataset of pictures (obtained by planes, satellites, and drones). In this study, we focused on the building of a deep learning model which will designed in such a way that it can detect wildfires using transfer learning methods from the best-trained deep learning computer vision architectures. Our proposed approach demonstrated its applicability in actual forest fire detection applications by achieving a detection rate of greater accuracy across various parameters.},
  keywords={Deep learning;Support vector machines;Natural resources;Humanities;Histograms;Satellites;Transfer learning;Detection;Specificity;Sensitivity;machine learning;GAN},
  doi={10.1109/ICCCNT56998.2023.10307785},
  ISSN={2473-7674},
  month={July},}@INPROCEEDINGS{10333282,
  author={Canello, Gianmarco and Mikhaylov, Konstantin and Hänninen, Tuomo},
  booktitle={2023 15th International Congress on Ultra Modern Telecommunications and Control Systems and Workshops (ICUMT)}, 
  title={Communication Perspective of Wildfire Detection and Suppression: A Survey of Technologies, Requirements, and Future Directions}, 
  year={2023},
  volume={},
  number={},
  pages={157-164},
  abstract={Wildfires have always been a risk to the environment and to human settlements; in the course of history, wildfire management methods have benefited from various technological breakthroughs. In the 20th century, it was the introduction of aerial fire suppression, but with the emergence of Artificial Intelligence (AI), Machine Learning (ML), and the latest telecommunication standards in the 21st century, there is potential for even more breakthroughs in wildfire management. In this paper, we collect, survey and systematise the recent research efforts that focus on wildfire detection and suppression. Departing from this state-of-the-art, we identify and discuss the communication requirements these methods imply and the potential technologies capable of addressing them. As a part of our contribution, we also introduce some exemplary results based on the developed simulation models allowing one to assess and analyse the connectivity requirements for Unmanned Aerial Vehicles(UAVs) assisted connectivity in a wildfire scenario. These results can serve as a reference for developing wireless connectivity solutions for wildfire control either based on a clean-state technology or for adopting existing technology, e.g., the 5G, for this use case.},
  keywords={Wireless communication;Surveys;5G mobile communication;Urban areas;Machine learning;Regulation;Reliability;wildfire;connectivity;requirements;communication;wireless;technology;IoT},
  doi={10.1109/ICUMT61075.2023.10333282},
  ISSN={2157-023X},
  month={Oct},}@INPROCEEDINGS{10126370,
  author={Sah, Shubham and Prakash, Suneet and Meena, Shweta},
  booktitle={2023 IEEE 8th International Conference for Convergence in Technology (I2CT)}, 
  title={Forest Fire Detection using Convolutional Neural Network Model}, 
  year={2023},
  volume={},
  number={},
  pages={1-5},
  abstract={Everyone recalls the destruction brought on by the Australian forest fires in 2019. Even though there isn’t much we can do to battle forest fires on our own, we can always rely on technology. By this we are trying to predict the accuracy of these models on forest fire data set. We are trying to detect forest fire in dense forest; our data set is very diverse and consist of images having forest fires, smokes, non-smoke and fire images. We have found out that Sensor detection and real-time geological data analysis are two methods for detecting forest fires. However, using image classification, for which Deep learning is the most efficient solution, is one of the best methods for detecting fire. In addition, these algorithms can be integrated with drones using deep learning techniques so that images can be taken frequently from the sky with ease, smoke can be detected in dense forests, and the authorities can be notified to take immediate action. The convolutional neural network algorithm for fire detection was the sole focus of our paper. The value of various epochs is used to evaluate these results.},
  keywords={Deep learning;Biological system modeling;Forestry;Predictive models;Cameras;Real-time systems;Recording;Machine learning;convolutional neural networks;algorithms;forest fire},
  doi={10.1109/I2CT57861.2023.10126370},
  ISSN={},
  month={April},}@INPROCEEDINGS{9787417,
  author={Ul Ain Tahir, Hoor and Waqar, Abdullah and Khalid, Shehzad and Usman, Syed Muhammad},
  booktitle={2022 2nd International Conference on Digital Futures and Transformative Technologies (ICoDT2)}, 
  title={Wildfire detection in aerial images using deep learning}, 
  year={2022},
  volume={},
  number={},
  pages={1-7},
  abstract={Wildfires are one of the most expensive and lethal natural disasters on the planet, destroying millions of hectares of forest resources and endangering the lives of people and animals. Such accidents are time-sensitive and can result in significant loss of life and property if not dealt with timely. Detection of fire at an early stage using aerial videos can reduce personal and property losses. This research focuses on the detection of fire locations monitored by UAV drones. Predicting fire behavior can assist firefighters in improved fire management and forecasting for future events, as well as lowering the firefighters' risk to life. Recent advancements in aerial imagery suggest that these images are valuable in the detection of wildfire. Drones and Unmanned Aerial Vehicles (UAVs) are among the different methods and technology for aerial imagery that is being used to obtain information about the fire. We present a YOLOv5 based deep learning model for fire detection. The proposed method detects fire in a real-time environment with high accuracy by evaluating a video frame-by-frame to detect such anomalies in real-time and sends a warning to the relevant authorities. In terms of detection performance, our technique outperforms existing fire detection systems. On the FireNet and FLAME aerial picture datasets, we evaluated the proposed method's performance and achieved the F1-score of 94.44%.},
  keywords={Deep learning;Measurement;Planets;Fires;Forestry;Autonomous aerial vehicles;Real-time systems;Fire Detection;YOLOv5;Forest Fire;Deep Learning;Aerial Images},
  doi={10.1109/ICoDT255437.2022.9787417},
  ISSN={},
  month={May},}@INPROCEEDINGS{9183707,
  author={Rashid, Md Tahmid and Zhang, Yang and Zhang, Daniel and Wang, Dong},
  booktitle={2020 16th International Conference on Distributed Computing in Sensor Systems (DCOSS)}, 
  title={CompDrone: Towards Integrated Computational Model and Social Drone Based Wildfire Monitoring}, 
  year={2020},
  volume={},
  number={},
  pages={43-50},
  abstract={Forest fires cause irreversible damages worldwide every year. Monitoring wildfire propagation is thus a vital task in mitigating forest fires. While computational model-based wildfire prediction methods provide reasonable accuracy in monitoring wildfire behavior, they are often limited due to the lack of constant availability of real-time meteorological data. In contrast, social-media-driven drone sensing (SDS) is emerging as a new sensing paradigm that detects the early signs of forest fires from online social media feeds and drives the drones for reliable sensing. However, due to the scarcity of social media data in remote regions and limited flight times of drones, SDS solutions often underperform in large-scale forest fires. In this paper, we present CompDrone, a wildfire monitoring framework that exploits the collective strengths of computational wildfire modeling and SDS for reliable wildfire monitoring. Two critical challenges exist to integrate computational modeling and SDS together: i) limited availability of social signals in the regions of a forest fire; and ii) predicting the regions of fire where the drones should be dispatched to. To solve the above challenges, the CompDrone framework leverages techniques from cellular automata, constrained optimization, and game theory. The evaluation results using a real-world wildfire dataset show that CompDrone outperforms the state-of-the-art schemes in effectively predicting wildfire propagation.},
  keywords={Sensors;Computational modeling;Drones;Social network services;Monitoring;Forestry;Predictive models;social sensing;computational modeling;UAV;wildfire},
  doi={10.1109/DCOSS49796.2020.00020},
  ISSN={2325-2944},
  month={May},}@INPROCEEDINGS{8711917,
  author={Alexandrov, Dmitriy and Pertseva, Elizaveta and Berman, Ivan and Pantiukhin, Igor and Kapitonov, Aleksandr},
  booktitle={2019 24th Conference of Open Innovations Association (FRUCT)}, 
  title={Analysis of Machine Learning Methods for Wildfire Security Monitoring with an Unmanned Aerial Vehicles}, 
  year={2019},
  volume={},
  number={},
  pages={3-9},
  abstract={The article is about the methods of machine learning, designed for the detection of wildfires using unmanned aerial vehicles. In the article presented the review of machine learning methods, described the motivation part of machine learning usage and comparison of fire and smoke detection is made. The research was focused on machine learning application for monitoring task with a restrictions according to scenarios of a real monitoring. The results of experiments with demonstration of effectiveness of detection are presented in the conclusion part.},
  keywords={Monitoring;Task analysis;Neural networks;Microsoft Windows;Drones;Deep learning},
  doi={10.23919/FRUCT.2019.8711917},
  ISSN={2305-7254},
  month={April},}@INPROCEEDINGS{10467597,
  author={Borah, Asha Rani and Ravi, Nikhil and Narayan, Nikhil and D'Souza, Prathik Joel},
  booktitle={2024 2nd International Conference on Intelligent Data Communication Technologies and Internet of Things (IDCIoT)}, 
  title={A Methodology for Forest Fire Detection and Notification Using AI and IoT Approaches}, 
  year={2024},
  volume={},
  number={},
  pages={168-173},
  abstract={This study explores how advanced technology has revolutionized the use of drones for forest fire surveillance. This research study explores the historical development of Unmanned Aerial Vehicles (UAVs) in forest monitoring with a focus on control systems and detection algorithms. The drone's capabilities are improved via telemetry integration, sophisticated autopilot systems, and an emphasis on accuracy, autonomy, and real-time communication. An analysis of object recognition, anomaly detection, and environmental monitoring algorithms in detail demonstrates how important a role these algorithms play in spotting dangers like forest fire. This study presents successful implementations through illustrative case studies, discusses obstacles, and lays forth future plans for utilizing drone technology for the forest fire surveillance in environmental conservation initiatives.},
  keywords={Temperature sensors;Heating systems;Surveillance;Forestry;Detectors;Sensor systems;Real-time systems;Cutting-edge technology;Forest surveillance drones;Control systems;Detection algorithms;Historical evolution;Unmanned Aerial Vehicles;Autonomy;Real-time communication},
  doi={10.1109/IDCIoT59759.2024.10467597},
  ISSN={},
  month={Jan},}@INPROCEEDINGS{10329033,
  author={Pavlenko, Volodymyr and Ponomarenko, Ihor and Morhulets, Oksana and Osadchyi, Viacheslav and Ponomarenko, Dmytro and Hrygorevska, Olena},
  booktitle={2023 IEEE 7th International Conference on Methods and Systems of Navigation and Motion Control (MSNMC)}, 
  title={Using Artificial Intelligence to Control Drones}, 
  year={2023},
  volume={},
  number={},
  pages={182-185},
  abstract={The importance of using drones to optimize results by types of economic activity is presented. The expediency of conducting comprehensive scientific research with the aim of finding new ways of using the presented technology and identifying ways to optimize the control of unmanned vehicles has been proven. It has been established that thanks to the improvement of the drone control system, it is possible to achieve qualitatively new results regarding the collection of various information and solving logistical problems in an extreme environment or conditions of uncertainty. The main factors of the active development of algorithms in the Data science, which allow optimizing various processes in the field of human activity, are presented. The importance of using server storage for the accumulation and processing of large arrays of heterogeneous information is revealed. Features of the transformation of the mathematical models use directions for data processing and the activation of the machine learning algorithms development are given. The reasons for the intensification of artificial intelligence introduction as a technology for making effective management decisions are revealed. The main directions of using artificial intelligence to optimize the management and operation of unmanned aerial vehicles are presented. A conceptual scheme of collection, accumulation and processing of heterogeneous information, which is generated by various devices placed on drones, and directions for applying artificial intelligence to achieve effective results are presented. The expediency of improving pattern recognition technology on a permanent basis has been proven, which will allow more accurate assessment of individual elements of the external environment and increase the efficiency of the logistics systems implementation. The possibility of using artificial intelligence for decision-making in conditions of uncertainty without the influence of the human factor and training on a permanent basis in accordance with the peculiarities of the influence of external and internal environment factors has been established. The expediency of conducting comprehensive research on the establishment of interaction between a certain number of unmanned aerial vehicles thanks to the use of artificial intelligence has been proven. The effectiveness of the drones' group use based on coordination algorithms and a control system implemented thanks to artificial intelligence has been established. The adaptability of interaction and the adoption of optimal decisions by the system of unmanned aerial vehicles during short periods of time in accordance with the manifestation of environmental factors have been proven.},
  keywords={Economics;Training;Technological innovation;Uncertainty;Autonomous aerial vehicles;Control systems;Servers;algorithms;artificial intelligence;big data;drones;logistics;pattern recognition},
  doi={10.1109/MSNMC61017.2023.10329033},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{9752298,
  author={Chandana, V. Sri and Vasavi, S.},
  booktitle={2022 International Conference on Electronics and Renewable Systems (ICEARS)}, 
  title={Autonomous drones based forest surveillance using Faster R-CNN}, 
  year={2022},
  volume={},
  number={},
  pages={1718-1723},
  abstract={Unmanned Aerial Vehicles (UAVs), often called drones, are airships that do not involve a human pilot or can carry any passengers. UAVs are an element of the Unmanned Aircraft System (UAS). They are accommodated with a ground station and a system to facilitate communication with the drone. UAVs can be controlled by a human operator using a remote control, as remotely-piloted aircraft (RPA), or with differing degrees of independence, from autopilot assistance to fully independent aircraft that does not require human interference. Lately, UAVs have been made capable of flying beyond visual line of sight (BVLOS), due to which autonomous drones have been used in various areas such as commercial, warfare, aerial photography, agriculture and forestry, and law enforcement. Autonomous drones are being used to perform aerial surveillance of forest areas to detect and locate forest fires. Various deep learning algorithms are implemented along with image processing techniques to create a robust mechanism for detecting fire and smoke from the images or video frames obtained from the UAVs. This paper studies and proposes how image processing models and techniques can be incorporated into Unmanned Aerial Vehicle systems to detect smoke and forest fires.},
  keywords={Visualization;Renewable energy sources;Surveillance;Image processing;Forestry;Autonomous aerial vehicles;Aircraft;Autonomous drones;Unmanned Aerial Vehicle;computer vision;image processing;Faster R-CNN;forest fire detection;smoke detection},
  doi={10.1109/ICEARS53579.2022.9752298},
  ISSN={},
  month={March},}@INPROCEEDINGS{10169409,
  author={Khemaissia, Seddik and Soufi, Youcef},
  booktitle={2023 IEEE 3rd International Maghreb Meeting of the Conference on Sciences and Techniques of Automatic Control and Computer Engineering (MI-STA)}, 
  title={Calamity classification in satellite and drone images using CNN and Transfer Learning}, 
  year={2023},
  volume={},
  number={},
  pages={738-743},
  abstract={Every year, natural disasters strike, wreaking havoc on lives, property, and the environment forever. They are unstoppable phenomena. In recent years, remote sensing imaging analysis has become increasingly important for the purpose of identifying and monitoring natural disasters in the context of climate change and environmental surveillance. The ability to convey a large amount of information in a single piece while still capturing the status of the underlying ground is one advantage of aerial or satellite imaging. Remotely sensed imagery has become increasingly important for environmental and climate monitoring in recent years, particularly for the detection and management of natural disasters. Using a convolutional neural network (CNN) to better extract the catastrophe characteristic, we propose autonomous natural disaster identification in this paper. CNN is resistant to shadows and is able to accurately determine the characteristics of a disaster. It is also able to avoid operator error, which can have an impact on the efficiency of disaster relief efforts. The images used as the model’s training data are divided into four categories: floods, cyclones, wildfires, and earthquakes. The input for disaster detection is either a live video stream or a video that has already been recorded. The study demonstrated that transfer learning can be used to accurately recognize natural disasters. We hope that the findings of this study will lead to the creation of monitoring or surveillance systems that are capable of accurately recognizing natural disasters in real-time. Based on the encouraging results, the suggested method may contribute to our understanding of deep learning’s role in catastrophe detection.},
  keywords={Satellites;Surveillance;Transfer learning;Earthquakes;Training data;Sea measurements;Streaming media;Climate change;Catastrophe detection;airborne image;transfer learning;CNN},
  doi={10.1109/MI-STA57575.2023.10169409},
  ISSN={},
  month={May},}@INPROCEEDINGS{9984404,
  author={Nuwantha, Maduka B. and Jayalath, Chamath N. and Rathnayaka, Malindu P. and Fernando, Dilusha C. and Rupasinghe, Lakmal and Chethana, Mihiri},
  booktitle={2022 13th International Conference on Computing Communication and Networking Technologies (ICCCNT)}, 
  title={A Drone-Based Approach for Deforestation Monitoring}, 
  year={2022},
  volume={},
  number={},
  pages={1-6},
  abstract={Most importantly the forests play a major role in providing worldwide oxygen and other essentials necessity. Monitoring the forest cover from above the forest canopy level can be easily done by retrieving images from the space satellites. Yet, it’s a great challenge to identify the deforestation as they are more complex. To overcome the complexity, the need of taking images from a considerable height is important. To do this part this research shows that unmanned ariel vehicles as knows as drones can do it conveniently and assist the process accurately. Monitoring the forest cover using drones is accurate but its challenging to break the barriers such as discovering objects and filtrate them to parts to process the correct data to arbitration as output. In this research project planned to design the image processing mechanism to success those mention obstacles to give successful output. To contribute the development of this research project in here using more effective approaches mostly using drones and automated software solution with getting help of less manpower on it. Utilization of the monitoring process is more effective with the real time image processing from the drone footages taken from the targeted site with the help of the software. The research is expecting the final output should be much as effective. Finally, this research project is scoping to track deforestation and we evaluated current literature on drone environmental applications, including forest monitoring, and drew on our own practical experience flying tiny drones to map and monitor tropical forests. Also, this project believes that the use of small drones can assist tropical communities in better managing and conserving the forests, while also benefiting partner organizations, governments, and forest data end-users, particularly those involved in forestry, biodiversity conservation, and climate change.},
  keywords={Degradation;Roads;Image processing;Area measurement;Forestry;Software;Agriculture;Digital Aerial Photogrammetry;biodiversity conservation;unmanned ariel vehicles;necessity;tropical forests;Deforestation;Drone;Image-Processing;Machine Learning;geographic information systems;Drone ecology Forest canopy Forest dynamics Remote sensing},
  doi={10.1109/ICCCNT54827.2022.9984404},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{9836119,
  author={Li, Shun and Qiao, Linhan and Zhang, Youmin and Yan, Jun},
  booktitle={2022 International Conference on Unmanned Aircraft Systems (ICUAS)}, 
  title={An Early Forest Fire Detection System Based on DJI M300 Drone and H20T Camera}, 
  year={2022},
  volume={},
  number={},
  pages={932-937},
  abstract={This paper presents a drone-based early forest fire detection system. Using multiple on-board aerial sensors, thermal images, RGB images, and distance between forest fire points and drones can be captured and determined from the air. To take advantage of data from different sources for forest fire detection and confirmation, both deep learning-based and traditional computer vision algorithms are developed and employed. The on-board computer and ground station computer are designed to work collaboratively according to the different complexity and computational demands of sub-modules in this system. By integrating different sensor data with a two-phase strategy for potential early forest fire detection and confirmation, the proposed system achieves a relatively low false alarm rate and has good robustness in the outdoor real-time early forest fire detection experiments with an on-board computer installed on a DJI M300 drone.},
  keywords={Image sensors;Computer vision;Forestry;Thermal sensors;Cameras;Sensor systems;Robustness},
  doi={10.1109/ICUAS54217.2022.9836119},
  ISSN={2575-7296},
  month={June},}@INPROCEEDINGS{9972070,
  author={Prabhu, Makarand and N B, Sai Shibu and Rao, Sethuraman N},
  booktitle={2022 IEEE 3rd Global Conference for Advancement in Technology (GCAT)}, 
  title={RescuTrack: An Edge Computing-Enabled Vitals Monitoring System for First Responders}, 
  year={2022},
  volume={},
  number={},
  pages={1-5},
  abstract={Natural disasters such as earthquakes, avalanches or events such as explosions and fire accidents frequently occur. Drone technology is a promising solution for disaster management where the mainstream communication infrastructure is unavailable or damaged. A swarm of drones serve as an Adhoc network to support rescue management activities. This project aims to design and develop an IoT-enabled Wireless Body Area Network (WBAN) to monitor the health status of Search and Rescue (SAR) teams in real-time in the event of floods and wildfires. The proposed WBAN architecture consists of the SAR team equipped with wearable body sensors, which collect health and environmental data for location determination and vital signs transmission. The Body Data Coordinator relays this data to the nearest gateway, equipped with an open-source, industry-grade middleware platform to allow data processing at the Edge and transmission to the Ground Control Station and further to the Cloud endpoint for further processing. There is a risk to personal health due to the arduous duties of first responders, which can cause high blood pressure among the SAR personnel and lead to acute cardiovascular events. There is a need to predict the risk of hypertension in first responders. This paper also discusses a time series-based forecasting algorithm to predict the BP Trends of the first resnonders involved in SAR activities.},
  keywords={Wireless communication;Wireless sensor networks;Computational modeling;Biological system modeling;Computer architecture;Body area networks;Personnel;Disaster Response;Edge Computing;SAR;IoT;Machine Learning;EdgeX Foundry},
  doi={10.1109/GCAT55367.2022.9972070},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{10574694,
  author={Nampoothiri, Kavita and Maheshwari, K N Uma and Sundar, S. and Padmini, T.N},
  booktitle={2024 3rd International Conference on Artificial Intelligence For Internet of Things (AIIoT)}, 
  title={Fire spread analysis and Fire detection using CNN}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={Early detection of forest fires allows for swift intervention, preventing the flames from spreading uncontrollably and safeguarding both human lives and the delicate ecosystems that thrive within our forests. Our study attempts to identify fire, locate its precise position relative to its surroundings, and determine its rate of spread. Initially, we begin with pre-processing the images using OpenCV, followed by segmentation of the same. As the images generated by the drone cameras are trained, a convolutional neural network model is built using the Keras API. The photographs can be categorized as “Fire” or “Non-Fire” with the aid of this model. Additionally, the rate at which the fire spreads over the measured area is also determined using the recorded footage. The normalized FLAME dataset is utilized to derive the outcomes for the suggested technique.},
  keywords={Location awareness;Wildfires;Forestry;Predictive models;Cameras;Software;Safety;CNN;FlaME dataset;Fire spread;Fire detection;OpenCV;Image Processing},
  doi={10.1109/AIIoT58432.2024.10574694},
  ISSN={},
  month={May},}@INPROCEEDINGS{9418227,
  author={Lohit, Gandham Venkata Sai and Bisht, Divyansh},
  booktitle={2021 5th International Conference on Computing Methodologies and Communication (ICCMC)}, 
  title={Seed Dispenser using Drones and Deep Learning Techniques for Reforestation}, 
  year={2021},
  volume={},
  number={},
  pages={1275-1283},
  abstract={As known already, Deforestation still continues to degrade the earth at an alarming rate, where it destroys the surrounding flora and fauna. According to the Food and Agriculture Organization of the United Nations it was estimated that between 2016 and 2020, the area of forest reduced from, 16 million hectares per year to 10 million hectares per year. The main and primary reason for this, is continuing to be the agricultural expansion and commercial production, which leads to loss of forest biodiversity. Almost 40 percent of the degradation is accounted to this factor. Looking into the bright side of forest it would bring around 86 million jobs, which would support the livelihood of many. In the world roughly around 870 million people spend time collecting wood for fuel (fuel-wood) to produce charcoal.One of the major effects caused by deforestation is the greenhouse effect, here the main gases namely CO2 (carbon-dioxide), CH4 (methane), NO2 (nitrogen dioxide) and cholofloro carbons. These gases trap the sunlight which fall in the IR range, this disturbs the equilibrium of the earth. In addition to this cutting trees also release CO2, adding to the rigid hold of these gases on the earth, which ultimately lead to the warming of the earth, this is very dangerous for humans and many lifeforms on earth.In this paper a novel solution to counter the problem of deforestation using drones and deep learning techniques has been proposed. The main reason of considering drones for this purpose is that it is fast as compared to traditional manual labor (almost 9 times faster), which saves time and improves efficiency. Moreover, a drone being unmanned avoids any risk of human danger, this method can be best suited for area effected by natural disaster like a forest fire in remote area, where people cannot travel, make reforestation at those areas relatively easy. Also, this method can be extended towards monitoring of the number of trees in a locality making it easier to keep tracks of the areas of interest. Moreover, with an expert steering the operations of seed dispersion, appropriate areas of sowing seeds can be found in different topologies with an advantage of object detection at these areas. Here a Mobile Net architecture is proposed and implemented for object detection using raspberry pi, which is embedded in the drone along with a seed dispenser, which will be used to sow the seeds at the barren or "deforested land".},
  keywords={Earth;Deep learning;Forestry;Vegetation;Object detection;Production;Organizations;Drones;MobileNet Architecutre;APM2.8;Seed Dispenser;Raspberry pi;Global Positioning Sysyem;Object Detection},
  doi={10.1109/ICCMC51019.2021.9418227},
  ISSN={},
  month={April},}@ARTICLE{10522748,
  author={Khosravi, Mohammadjavad and Arora, Rushiv and Enayati, Saeede and Pishro-Nik, Hossein},
  journal={IEEE Transactions on Automation Science and Engineering}, 
  title={A Search and Detection Autonomous Drone System: From Design to Implementation}, 
  year={2024},
  volume={},
  number={},
  pages={1-17},
  abstract={Utilizing autonomous drones or unmanned aerial vehicles (UAVs) has shown great advantages over preceding methods in support of urgent scenarios such as search and rescue (SAR) and wildfire detection. In these operations, search efficiency in terms of the amount of time spent to find the target is crucial since with time the survivability of the missing person decreases or wildfire management becomes more difficult with disastrous consequences. In this work, we consider the scenario where a drone is intended to search and detect a missing person (e.g., a hiker or a mountaineer) or a potential fire spot in a given area. To obtain the shortest path to the target, a general framework is provided to model the problem of target detection when the target’s location is probabilistically known. To this end, two algorithms are proposed: Path planning and target detection. The path planning algorithm is based on Bayesian inference and the target detection is accomplished by using a residual neural network (ResNet) trained on the image dataset captured by the drone as well as existing pictures and datasets on the web. Through simulation and experiment, the proposed path planning algorithm is compared with two benchmark algorithms. It is shown that the proposed algorithm significantly decreases the average time of the mission. Note to Practitioners—This article is motivated by the need for an efficient path-planning algorithm for drones during specific SAR operations. In particular, situations where someone is lost in a snow-covered hike and a fire spot that is in its initial levels are of interest. In fact, since the target location is not known, it is required that the UAV be able to efficiently search the entire area until it finds the target in the shortest possible time. The proposed Bayesian framework along with the ResNet learning algorithm shows an efficient performance in terms of average time duration and accuracy, respectively. The framework developed in this paper can be extended to a multi-UAV scenario where UAVs coordinate to optimize the overall performance.},
  keywords={Drones;Autonomous aerial vehicles;Path planning;Object detection;Wildfires;Surveillance;Probabilistic logic;Autonomous drones;unmanned aerial vehicles (UAVs);search and rescue (SAR);fire detection;path planning;machine learning},
  doi={10.1109/TASE.2024.3395409},
  ISSN={1558-3783},
  month={},}@INPROCEEDINGS{10556912,
  author={Rolland, Edouard G. A. and Grøntved, Kasper A. R. and Christensen, Anders Lyhne and Watson, Matthew and Richardson, Tom},
  booktitle={2024 International Conference on Unmanned Aircraft Systems (ICUAS)}, 
  title={Autonomous UAV Volcanic Plume Sampling Based on Machine Vision and Path Planning}, 
  year={2024},
  volume={},
  number={},
  pages={1064-1071},
  abstract={Drones currently serve as a valuable tool for in-situ sampling of volcanic plumes, but they still involve manual piloting. In this paper, we enable autonomous dual plume sampling by using a machine vision model to detect eruptions. When an eruption is detected, a sampling trajectory is automatically generated to intercept the plume twice to collect comparative samples. The machine vision model is developed by training a YOLOv8 object detection model thanks to a database of 1505 images that feature labelled plumes. The obtained average precision value of the model's plume class, at 90.7%, is comparable to that of state-of-the-art models for wildfire smoke monitoring. The performance of this method is assessed using a software-in-the-loop simulation of the drone and a simulated plume model. Although the results confirm the efficacy of using a machine vision model for triggering an onboard path-planning algorithm, it also suggests the potential for a hybrid strategy that integrates visual servoing with our proposed path-planning approach.},
  keywords={Training;Wildfires;Machine vision;Object detection;Manuals;Feature extraction;Visual servoing},
  doi={10.1109/ICUAS60882.2024.10556912},
  ISSN={2575-7296},
  month={June},}@INPROCEEDINGS{10226139,
  author={Boone, Julia and Hopkins, Bryce and Afghah, Fatemeh},
  booktitle={IEEE INFOCOM 2023 - IEEE Conference on Computer Communications Workshops (INFOCOM WKSHPS)}, 
  title={Attention-Guided Synthetic Data Augmentation for Drone-based Wildfire Detection}, 
  year={2023},
  volume={},
  number={},
  pages={1-6},
  abstract={Drone-based wildfire detection models allow for real-time fire monitoring which is critical for the most efficient intervention and mitigation techniques needed for wildfires. However, due to restrictions on the usage of UAVs during wildfires and prescribed burns, current UAV-sourced wildfire imagery datasets are limited to images of individual burns. While deep learning fire detection models trained and tested on these datasets can achieve high fire classification accuracy, these models fail to generalize when given images of wildfires from other forestry types due to the differences in vegetation, climate, time of year, and other factors that contribute to the visual appearance of these burns. Synthetic augmentation techniques can increase the diversity of training datasets. In this work, we develop an attention-guided image-to-image translation tool that utilizes Generative Adversarial Networks (GANs) to generate wildfire images from aerial forestry images in order to increase classification accuracy. We illustrate the need for attention mechanisms for generating wildfire images through image-to-image translation techniques. We observe increased classification accuracy for a test set based on a separate burn from the training dataset when augmenting training data with diverse synthetic wildfire images.},
  keywords={Training;Visualization;Fires;Vegetation mapping;Training data;Forestry;Generative adversarial networks;GANs;image-to-image translation;attention-guided image-to-image translation;data-driven fire detection},
  doi={10.1109/INFOCOMWKSHPS57453.2023.10226139},
  ISSN={2833-0587},
  month={May},}@INPROCEEDINGS{10621462,
  author={Meleti, Uma and Razi, Abolfazl and Afghah, Fatemeh},
  booktitle={2024 20th International Conference on Distributed Computing in Smart Systems and the Internet of Things (DCOSS-IoT)}, 
  title={Obscured Wildfire Flame Detection by Spatio-temporal Analysis of Smoke Patterns Using Frame-wise Transformers}, 
  year={2024},
  volume={},
  number={},
  pages={58-65},
  abstract={In this paper, we propose a new paradigm in wildfire management for detecting both visible and obscured fire using Deep Learning (DL). The essence of our method is the joint spatial and temporal analysis of RGB videos, embracing the fact that temporal patterns of smoke motions in consecutive video frames can indicate obscured fire flames. This perspective contrasts the traditional approach of independently analyzing images and individual video frames. To this end, we propose a frame-wise transformer architecture that applies an attention mechanism between the consecutive frames while preserving spatial information within frames as opposed to regular attention mechanisms like the non-local block, which combines spatial and temporal information into a single vector. We also optimize the temporal pattern lengths under different spatial resolutions to achieve the highest performance while reducing the computational cost. To investigate the applicability of our method in aerial image processing, we applied it to a curated version of the FLAME2 dataset that includes dual-mode RGB/IR videos. The IR video feed is used to extract ground truth, while the model is trained only on RGB videos to maintain applicability to low-cost commercial drones (which are equipped only with regular cameras) and facilitate processing existing RGB-only datasets. Our proposed method achieves a Segmentation Foreground Dice score of 92.61%, an Object Detection Precision and Recall rate of 93.21% and 91.73%, and clip-level classification accuracy of 98.02%, respectively. We also investigated the efficacy and generalizability of our method through ablation study 1.},
  keywords={Attention mechanisms;Wildfires;Computer architecture;Transformers;Synchronization;Feeds;Spatial resolution;Wildfire Monitoring;Obscured Fire Detection;Unmanned Aerial Vehicles;Temporal Video Analysis},
  doi={10.1109/DCOSS-IoT61029.2024.00019},
  ISSN={2325-2944},
  month={April},}@INPROCEEDINGS{8885873,
  author={Zanol, Riccardo and Chiariotti, Federico and Zanella, Andrea},
  booktitle={2019 IEEE Wireless Communications and Networking Conference (WCNC)}, 
  title={Drone mapping through multi-agent reinforcement learning}, 
  year={2019},
  volume={},
  number={},
  pages={1-7},
  abstract={In recent years, the use of drones to map environments and survey them for items of interest such as forest fires, landslides or wild animals has gained traction in various research communities. However, the need for a human pilot or a pre-planned flight path severely limits the effectiveness of the drones, especially when a whole swarm is used. In this work, we propose a model of the drone survey problem and apply three well-known reinforcement learning strategies, showing that the performance loss due to the lack of explicit optimization and pre-programmed knowledge of the system statistics is negligible in the swarm scenario.},
  keywords={Batteries;Drones;Markov processes;Power demand;Three-dimensional displays;Data models;State of charge},
  doi={10.1109/WCNC.2019.8885873},
  ISSN={1558-2612},
  month={April},}@INPROCEEDINGS{10252566,
  author={Nayak, Vaishnavi Y and Rao, Vaishnavi G and H, Jagruthi},
  booktitle={2023 3rd International Conference on Electrical, Computer, Communications and Mechatronics Engineering (ICECCME)}, 
  title={Drones in Forest Fire Mitigation}, 
  year={2023},
  volume={},
  number={},
  pages={1-7},
  abstract={The proposed system in this paper utilizes drones and Convolutional Neural Networks (CNN) for fire detection. Traditional smoke sensors can be slow and cost-inefficient, making them less suitable for early fire detection. The authors analyze the scope of CNN and related methodologies for detecting fire and propose a novel system that uses optical cameras mounted on drones to detect and identify forest fire threats in real-time. The system also aims to notify interested parties and authorities by providing alerts and important information such as the specific location and environmental conditions. The use of drones equipped with optical cameras is an innovative approach to early fire detection. The ability of drones to capture images and transmit them in real-time enables the detection and identification of forest fires as they occur. The use of CNN allows for the efficient and accurate analysis of the captured images, resulting in a reliable detection system. Additionally, the system can send alerts to authorities and interested parties, allowing for timely and appropriate action to be taken. Overall, the proposed system has the potential to revolutionize early fire detection and response. The use of modern technology such as drones and CNN can greatly improve the efficiency and accuracy of fire detection, ultimately leading to a safer and more secure environment.},
  keywords={Training;Training data;Forestry;Optical imaging;Cameras;Real-time systems;Convolutional neural networks;forest fires;UAV;drones;CNN;images;hazard;Machine learning;classification;object detection;alert;warnings},
  doi={10.1109/ICECCME57830.2023.10252566},
  ISSN={},
  month={July},}@INPROCEEDINGS{10560880,
  author={K, Srinath and B, Sri Sathya K. and S, Raguvaran and K, Vachan Girish and K, Vidith and V, Sriram},
  booktitle={2024 International Conference on Science Technology Engineering and Management (ICSTEM)}, 
  title={Integrated Forest Fire Detection System for Identifying Living Beings Using Drones by Employing Custom TrainedYOLOv5 Model}, 
  year={2024},
  volume={},
  number={},
  pages={1-7},
  abstract={The substantial threat of forest fires impacts both the environment and humankind. Early detection of these fires plays apivotal role in effective fire fighting and minimizing damage. Addressing the challenges of identifying living beings amidst forest fires is crucial for effective emergency response. This research proposes a comprehensive approach by implementing Unmanned Aerial Vehicles (UAVs) integrated with advanced object detection technology to locate and identify animals and humans during such disasters. By employing a custom-trained Efficient YOLOv5 model specifically optimized for aerial views, the system achieves a mean Average Precision (mAP) of 0.828 at a confidence threshold of 0.5, demonstrating a reliable performance in detecting various living beings. Integration of this technology into an alert system enables real-time updates on the locations of living beings, facilitating timely and efficient rescue efforts. The proposed methodology not only enhances the effectiveness of emergency response teams but also contributes to minimizing the loss of life and property caused by forest fires.},
  keywords={YOLO;Wildfires;Wildlife;Sociology;Forestry;Emergency services;Autonomous aerial vehicles;YOLOv5 Model;Unmanned Aerial Vehicles (UAV);Forest Fire;Object Detection and Wildlife Animals},
  doi={10.1109/ICSTEM61137.2024.10560880},
  ISSN={},
  month={April},}@INPROCEEDINGS{10710928,
  author={Akkurt, Ramazan and Kahveci, Semih and Yetgin, Zeki and Avaroğlu, Erdinç and Keleş, Hakan},
  booktitle={2024 8th International Artificial Intelligence and Data Processing Symposium (IDAP)}, 
  title={Detecting Red Pine Seedlings with YOLOv8: A Labeling Method Comparison}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={The detection and periodic monitoring of small pine seedlings are crucial for effective forest management. However, the presence of weeds in the field makes it difficult to detect small pine seedlings, necessitating the use of new techniques to address the challenge. The success of the techniques used in the field of object detection depends on various factors. The labeling technique used for the dataset is among the most important of these factors. In this work, we examine the impact of different data labeling techniques on the success of the YOLOv8 object detection algorithm in detecting small pine seedlings. Within the scope of the work, we created a dataset by labeling drone images taken from the Mersin Yeşilovacık forest area using both polygon and bounding box methods and analyzed the performance of YOLOv8 Large and Nano models. According to the results, the polygon method performed better than the bounding box method. Additionally, the YOLOv8 Large model is superior to the Nano model in both labeling methods.},
  keywords={Analytical models;Object detection;Forestry;Learning (artificial intelligence);Data processing;Labeling;Monitoring;Drones;object detection;yolov8;tree detection;red pine tree;deep learning},
  doi={10.1109/IDAP64064.2024.10710928},
  ISSN={},
  month={Sep.},}@INPROCEEDINGS{8756696,
  author={Kinaneva, Diyana and Hristov, Georgi and Raychev, Jordan and Zahariev, Plamen},
  booktitle={2019 42nd International Convention on Information and Communication Technology, Electronics and Microelectronics (MIPRO)}, 
  title={Early Forest Fire Detection Using Drones and Artificial Intelligence}, 
  year={2019},
  volume={},
  number={},
  pages={1060-1065},
  abstract={Forest and urban fires have been and still are serious problem for many countries in the world. Currently, there are many different solutions to fight forest fires. These solutions mainly aim to mitigate the damage caused by the fires, using methods for their early detection. In this paper, we discuss a new approach for fire detection and control, in which modern technologies are used. In particular, we propose a platform that uses Unmanned Aerial Vehicles (UAVs), which constantly patrol over potentially threatened by fire areas. The UAVs also utilize the benefits from Artificial Intelligence (AI) and are equipped with on-board processing capabilities. This allows them to use computer vision methods for recognition and detection of smoke or fire, based on the still images or the video input from the drone cameras. Several different scenarios for the possible use of the UAVs for forest fire detection are presented and analyse in the paper, including a solution with the use of a combination between a fixed and rotary-wing drones.},
  keywords={early forest fire detection platform;drones;UAVs;artificial intelligence;computer vision},
  doi={10.23919/MIPRO.2019.8756696},
  ISSN={2623-8764},
  month={May},}@INPROCEEDINGS{8479143,
  author={Gokaraju, Balakrishna and Agrawal, Rajeev and Doss, Daniel Adrian and Bhattacharya, Sambit},
  booktitle={SoutheastCon 2018}, 
  title={Identification of Spatio- Temporal Patterns in Cyber Security for Detecting the Signature Identity of Hacker}, 
  year={2018},
  volume={},
  number={},
  pages={1-5},
  abstract={The internet communication infrastructure built using various advanced network topologies impact critical dynamics in current revenue, societal, and military activities. However, these hi-tech infrastructures are facing overwhelmingly severe cyber-security threats on the global scale. The existing theoretical works focuses on understanding the complex topologies of the Internet and applying counter measures after large scale failures, but constantly were overlooking that there could be any existence of intrinsic patterns of cyberattacks, not only in temporal frequencies but also in consecutive IP region referred to as geo-spatial coordinates (also referred as Spatio). Previous literature favors non-existent of such patterns due to the complexity and large span of the cyberspace. Surprisingly, through a detailed analysis of spatiotemporal large datasets, we theoretically would be able to uncover intrinsic “spatiotemporal patterns” in the underlying cyberattacks. These above patterns can uncover the hacker's attack “fingerprints” and target selection scheme by identifying the very limited pattern of unique spatiotemporal characteristics over the consecutive IP addresses. We will provide the proof-of-concept and further extend the work towards experimentation with cyber security data.},
  keywords={Data mining;Data models;IP networks;Predictive models;Machine learning;Fires;Knowledge discovery;Robotics;Autonomous;PID Controls;Drones;Precision},
  doi={10.1109/SECON.2018.8479143},
  ISSN={1558-058X},
  month={April},}@INPROCEEDINGS{8479078,
  author={Gokaraju, Balakrishna and Agrawal, Rajeev and Doss, Daniel Adrian and Bhattacharya, Sambit},
  booktitle={SoutheastCon 2018}, 
  title={Identification of Spatio-Temporal Patterns in Cyber Security for Detecting the Signature Identity of Hacker}, 
  year={2018},
  volume={},
  number={},
  pages={1-5},
  abstract={The internet communication infrastructure built using various state-of-the-art network topologies play critical dynamics in current economic, societal, and military activities. However, these hi-tech infrastructures are facing overwhelmingly severe cyber-security challenges on the global scale. The existing theoretical works focused on understanding the complex topologies of the Internet and on the likelihood of large scale failures, but constantly were overlooking that there could be any existence of intrinsic patterns of cyberattacks, not only in temporal frequencies but also in consecutive IP region referred to as geo-spatial coordinates (also referred as Spatio). Previous literature favors non-existent of such patterns due to the complexity of the cyberspace. Surprisingly, through a detailed analysis of spatiotemporal large datasets, we successfully would be able to uncover intrinsic “spatiotemporal patterns” in the underlying cyberattacks. These above patterns can uncover the hacker's attack “fingerprints” and target selection scheme by identifying the very limited number of unique spatiotemporal characteristics over the consecutive IP addresses. We will provide the proof-of-concept and further extend the work towards experimentation with cyber security data.},
  keywords={Data mining;Data models;IP networks;Predictive models;Machine learning;Fires;Knowledge discovery;Robotics;Autonomous;PID Controls;Drones;Precision},
  doi={10.1109/SECON.2018.8479078},
  ISSN={1558-058X},
  month={April},}@INPROCEEDINGS{10121881,
  author={Choutri, Kheiredddine and Fadloun, Samiha and Lagha, Mohand and Bouzidi, Farah and Charef, Wided},
  booktitle={2022 International Conference on Artificial Intelligence of Things (ICAIoT)}, 
  title={Forest Fire Detection Using IoT Enabled UAV And Computer Vision}, 
  year={2022},
  volume={},
  number={},
  pages={1-6},
  abstract={Owing to their rapid response capabilities, extended range and improved personnel safety, drones equipped with sensors for forest fire monitoring can process the information through sensors and IoT application. Despite this, existing drone-based forest fire detection systems still present many practical problems for their use in operational conditions. In particular, successful detection of forest fires remains difficult, given the very complicated and unstructured forest environments, the movement of UAV-mounted cameras. These negative effects can seriously cause false alarms or faulty detection. In order to perform this mission, meet the corresponding performance criteria and overcome these increasing challenges, it is essential to investigate ways to increase the probability of successful detection and improve the adaptation capabilities to various circumstances in order to improve the accuracy of the forest fire detection system. Based on the above requirements, this paper focuses on the development of reliable and accurate forest fire detection algorithms applicable to drones. For that purpose, many CNN architectures were trained and compared to detect fire. Obtained results demonstrate the accuracy of the developed system compared to traditional detection algorithms.},
  keywords={Forestry;Sensors;Stereo vision;Safety;Internet of Things;Reliability;Personnel;UAV;Deep learning;Stereo vision;Artificial intelligence;Forest fire detection},
  doi={10.1109/ICAIoT57170.2022.10121881},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{10543925,
  author={Gaur, Samta and Kumar, J. Sathish and Shukla, Shailendra},
  booktitle={2024 IEEE 9th International Conference for Convergence in Technology (I2CT)}, 
  title={A Comparative Assessment of CNN-Sigmoid and CNN-SVM model for Forest Fire Detection}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={Forest fires present a notable danger to the environment, wildlife, and human lives. Early detection of forest fire is crucial to prevent their spread and minimize damage. The timely detection and response to forest fires are paramount to mitigating their destructive impact. Yet, conventional methods like visual inspection and ground patrols are labor-intensive, time-consuming, and demand extensive coverage. Recently, machine learning algorithms for image detection have emerged as an effective approach for detecting forest fire using forest fire images taken from drone. This study aims to evaluate the effectiveness of Convolution Neural Network with Sigmoid (CNN-Sigmoid) and Convolution Neural Network with Support Vector Machine (CNN-SVM) model to detect forest fire (on Forest Fire Dataset). Through our experimental result we have found that the extraction using CNN and classification using SVM has improved the training accuracy (99.87%) and validation accuracy (97.11%) of CNN-SVM model compared to CNN-Sigmoid. This observation was substantiated by the CNN-SVM achieving a test accuracy of 96.84%, while the CNN-Sigmoid attained a test accuracy of 95.79%.},
  keywords={Support vector machines;Training;Visualization;Machine learning algorithms;Convolution;Neural networks;Wildlife;Forest Fire Detection;Convolution Neural Network (CNN);Support Vector Machine (SVM);CNN-SVM;CNN-Sigmoid;Forest Fire Dataset},
  doi={10.1109/I2CT61223.2024.10543925},
  ISSN={},
  month={April},}@INPROCEEDINGS{9723699,
  author={Zhanying, Zhang and Xinyuan, Chen},
  booktitle={2021 International Conference on Intelligent Computing, Automation and Systems (ICICAS)}, 
  title={Research on Forest Fire Detection Algorithm Based on Yolov5}, 
  year={2021},
  volume={},
  number={},
  pages={354-357},
  abstract={An important mean of early forest fire warning is observation of the scene by the fire prevention center around the clock. Traditional monitoring techniques include manual observation, dedicated patrols and satellite detection. With the rapid development of computer vision technology, image identification has been widely used in fields like agriculture, medical treatment, environmental protection, etc. This article mainly uses image identification technology to detect the smoke and flame produced by forest fire. By analyzing the pictures taken by the camera of the drone, the relevant features of smoke and flame areas are extracted for fire recognition and location.},
  keywords={Training;Satellites;Fires;Medical treatment;Forestry;Manuals;Feature extraction;Image Identification;YOLOv5;Forest Fire Detection},
  doi={10.1109/ICICAS53977.2021.00080},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{10235675,
  author={Jia, Xuanbo and Wang, Yike and Chen, Taiming},
  booktitle={2023 IEEE 5th International Conference on Power, Intelligent Computing and Systems (ICPICS)}, 
  title={Forest Fire Detection and Recognition Using YOLOv8 Algorithms from UAVs Images}, 
  year={2023},
  volume={},
  number={},
  pages={646-651},
  abstract={In recent years, forest fires have been frequent in many places, but there is a lack of effective and systematic methods to detect forest fires. Therefore, this paper proposes a forest fire detection strategy: a system that can be built with a large number of pre-processed and pre-trained datasets, receive images captured by UAVs and calculate the fire occurrence rate through algorithms and quickly pass them to users, thus speeding up possible rescue operations. For the system equipped with algorithmic models, this paper conducts an in-depth study of the YOLO series technology in image recognition. Based on the dataset of high-definition forest fire images captured by drones, the YOLOv8, YOLOv7 and YOLOv5 models are analyzed and compared from two perspectives: the accuracy of fire detection and the speed of model training, and it is found that YOLOv8 has the best accuracy and achieves a good balance between accuracy and computational speed. Based on this result, the proposed model is dependent on the nano-sized YOLOv8 algorithm, which has a fairly high accuracy, closely matches the original fire-containing test image, and still has a stable performance in detecting small fires. This algorithmic model in combination with the above system can help to accurately identify the occurrence of fires and thus mitigate the damage to forest resources.},
  keywords={Training;Deep learning;Analytical models;Image recognition;Systematics;Computational modeling;Face recognition;YOLO series technology;Image recognition;YOLOv8 model},
  doi={10.1109/ICPICS58376.2023.10235675},
  ISSN={2834-8567},
  month={July},}@ARTICLE{9953997,
  author={Chen, Xiwen and Hopkins, Bryce and Wang, Hao and O’Neill, Leo and Afghah, Fatemeh and Razi, Abolfazl and Fulé, Peter and Coen, Janice and Rowell, Eric and Watts, Adam},
  journal={IEEE Access}, 
  title={Wildland Fire Detection and Monitoring Using a Drone-Collected RGB/IR Image Dataset}, 
  year={2022},
  volume={10},
  number={},
  pages={121301-121317},
  abstract={Current forest monitoring technologies including satellite remote sensing, manned/piloted aircraft, and observation towers leave uncertainties about a wildfire’s extent, behavior, and conditions in the fire’s near environment, particularly during its early growth. Rapid mapping and real-time fire monitoring can inform in-time intervention or management solutions to maximize beneficial fire outcomes. Drone systems’ unique features of 3D mobility, low flight altitude, and fast and easy deployment make them a valuable tool for early detection and assessment of wildland fires, especially in remote forests that are not easily accessible by ground vehicles. In addition, the lack of abundant, well-annotated aerial datasets – in part due to unmanned aerial vehicles’ (UAVs’) flight restrictions during prescribed burns and wildfires – has limited research advances in reliable data-driven fire detection and modeling techniques. While existing wildland fire datasets often include either color or thermal fire images, here we present (1) a multi-modal UAV-collected dataset of dual-feed side-by-side videos including both RGB and thermal images of a prescribed fire in an open canopy pine forest in Northern Arizona and (2) a deep learning-based methodology for detecting fire and smoke pixels at accuracy much higher than the usual single-channel video feeds. The collected images are labeled to “fire” or “no-fire” frames by two human experts using side-by-side RGB and thermal images to determine the label. To provide context to the main dataset’s aerial imagery, the included supplementary dataset provides a georeferenced pre-burn point cloud, an RGB orthomosaic, weather information, a burn plan, and other burn information. By using and expanding on this guide dataset, research can develop new data-driven fire detection, fire segmentation, and fire modeling techniques.},
  keywords={Data models;Fires;Autonomous aerial vehicles;Deep learning;Forests;Monitoring;Satellite navigation systems;Remote sensing;Data-driven fire detection;prescribed fire;fire modeling;fire data;unmanned aerial vehicle (UAV);deep learning},
  doi={10.1109/ACCESS.2022.3222805},
  ISSN={2169-3536},
  month={},}@ARTICLE{10470440,
  author={Akram, Junaid and Anaissi, Ali and Othman, Wajdy and Alabdulatif, Abdulatif and Akram, Awais},
  journal={IEEE Transactions on Consumer Electronics}, 
  title={DroneSSL: Self-Supervised Multimodal Anomaly Detection in Internet of Drone Things}, 
  year={2024},
  volume={70},
  number={1},
  pages={4287-4298},
  abstract={In this study, we introduce a pioneering framework, DroneSSL, that integrates the concept of spatial crowdsourcing with TinyML to enhance anomaly detection in the Internet of Drone Things (IoDT). This innovative approach leverages drones and unmanned ground vehicles (UGVs) for expansive data collection in environments that are typically inaccessible or hazardous, such as during Australian bushfire incidents. By employing lightweight machine learning models alongside advanced communication technologies, DroneSSL transcends traditional spatial-temporal data analysis methods. It efficiently processes multimodal data from diverse Points-of-Interest (PoIs), significantly improving the quality and speed of data collection and analysis. The framework’s integration of a temporal feature extraction module with a Graph Neural Network (GNN) and its adaptable, scalable GNN architecture tailor DroneSSL for real-time operations in resource-constrained IoDT environments. Achieving an 89.6% F1 score, DroneSSL marks a substantial 4.9% improvement over existing approaches, highlighting its effectiveness in critical applications such as environmental surveillance and emergency response. This advancement not only showcases the potential of combining TinyML with spatial crowdsourcing for IoDT but also sets a new standard for efficient, scalable anomaly detection, paving the way for future innovations in IoT edge devices and environmental monitoring systems.},
  keywords={Drones;Anomaly detection;Graph neural networks;Crowdsourcing;Correlation;Data models;Training;Self-supervised learning;autoencoder;GNN;anomaly detection;drones;data fusion;TinyML},
  doi={10.1109/TCE.2024.3376440},
  ISSN={1558-4127},
  month={Feb},}@INPROCEEDINGS{9049048,
  author={Islam, Shafkat and Huang, Qiyuan and Afghah, Fatemeh and Fule, Peter and Razi, Abolfazl},
  booktitle={2019 53rd Asilomar Conference on Signals, Systems, and Computers}, 
  title={Fire Frontline Monitoring by Enabling UAV-Based Virtual Reality with Adaptive Imaging Rate}, 
  year={2019},
  volume={},
  number={},
  pages={368-372},
  abstract={Recently, using drones for forest fire management has gained a lot of attention from the research community due to their advantages such as low operation and deployment cost, flexible mobility, and high-quality imaging. It also minimizes human intervention, especially in hard-to-reach areas where the use of ground-based infrastructure is troublesome. Drones can provide virtual reality to firefighters by collecting on-demand high-resolution images with adjustable zoom, focus, and perspective to improve fire control and eliminate human hazards. In this paper, we propose a novel model for fire expansion as well as a distributed algorithm for drones to relocate themselves towards the front-line of an expanding fire field. The proposed algorithm comprises a light-weight image processing for fire edge detection that is highly desirable over computational expensive deep learning methods for resource-constrained drones. The positioning algorithm includes motions tangential and normal to fire frontline to follow the fire expansion while keeping minimum pairwise distances for collision avoidance and non-overlapping imaging. We proposed an action-reward mechanism to adjust the drones’ speed and processing rate based on the fire expansion rate and the available onboard processing power. Simulations results are provided to support the efficacy of the proposed algorithm.},
  keywords={UAV networks;fire monitoring;virtual reality;autonomous control;image-based edge detection},
  doi={10.1109/IEEECONF44664.2019.9049048},
  ISSN={2576-2303},
  month={Nov},}@INPROCEEDINGS{10465865,
  author={Bathalapalli, Sarang and Prasad, P. Krishna and Ponnala, Ramesh},
  booktitle={2023 International Conference on Advances in Computation, Communication and Information Technology (ICAICCIT)}, 
  title={A Deep Learning Approach to Forest Fire Detection and Monitoring}, 
  year={2023},
  volume={},
  number={},
  pages={263-268},
  abstract={Forest fires pose a significant threat to sensitive ecosystems worldwide. Early detection and monitoring of these fires are critical for improving response times and aiding firefighting and evacuation efforts. This research paper proposes an approach that utilizes Convolutional neural network (CNN) based transfer learning models in conjunction with drone-derived images to accurately detect and differentiate between fire and nonfire images. This automated system enhances the efficiency of forest patrols and rapid-fire detection without human intervention. Pre-trained CNNs, including MobileNetV2, ResNet50, Xception, and VGG16, were fine-tuned using a dataset containing forest fire and nonfire images. A sigmoid classifier in the classification layer predicts the probability of an image being a fire or nonfire. Experimental results demonstrate the models' ability to identify fires across various scenarios with competitive processing times, making them highly deployable in forest settings.},
  keywords={Performance evaluation;Embedded systems;Image edge detection;Biological system modeling;Transfer learning;Forestry;Computer architecture;Forest Fire detection;ResNet50;MobileNetV2;VGG16;Xception;ImageNet;Transfer Learning;CNN},
  doi={10.1109/ICAICCIT60255.2023.10465865},
  ISSN={},
  month={Nov},}@ARTICLE{10474427,
  author={Haq, Bushra and Ali Jamshed, Muhammad and Ali, Kamran and Kasi, Bakhtiar and Arshad, Saira and Khan Kasi, Mumraiz and Ali, Imran and Shabbir, Aqsa and Abbasi, Qammer H. and Ur-Rehman, Masood},
  journal={IEEE Internet of Things Journal}, 
  title={Tech-Driven Forest Conservation: Combating Deforestation With Internet of Things, Artificial Intelligence, and Remote Sensing}, 
  year={2024},
  volume={11},
  number={14},
  pages={24551-24568},
  abstract={Deforestation poses a significant global environmental challenge with far-reaching consequences for biodiversity, climate change, and livelihoods. In this context, applying advanced technologies, such as the Internet of Things (IoT) and artificial intelligence (AI), holds immense promise. This article aims to comprehensively review and analyze the role of IoT, AI, and remote sensing technologies in monitoring, detecting, predicting, and preventing deforestation. By providing real-time data and enabling early detection, these technologies contribute to addressing activities like illegal logging, plant diseases, and forest fires. This review presents an overview of the advantages and limitations of these technologies, accompanied by an analysis of their current state and future potential. Key technologies covered include IoT, satellite imagery, drones, and AI algorithms, with each offering unique applications. Importantly, this article underscores the significance of these technologies in protecting forests and the diverse species they support. The findings discussed herein aim to inform ongoing debates and provide a foundation for further research in this crucial domain. Ultimately, the knowledge gained from this research has the potential to guide practical interventions and policies for effective forest conservation.},
  keywords={Forestry;Deforestation;Artificial intelligence;Wireless sensor networks;Environmental monitoring;Internet of Things;Vegetation;Climate change;Deforestation;Remote sensing;Deep learning;Machine learning;Biodiversity;Energy conservation;Satellite images;Artificial intelligence (AI);deep learning (DL);deforestation;image processing;Internet of Things (IoT);machine learning (ML);remote sensing;wireless sensor networks (WSNs)},
  doi={10.1109/JIOT.2024.3378671},
  ISSN={2327-4662},
  month={July},}@INPROCEEDINGS{9843479,
  author={Jafari, Hossein and Blasch, Erik and Pham, Khanh and Chen, Genshe},
  booktitle={2022 IEEE Aerospace Conference (AERO)}, 
  title={Signature-Aware RF Exploitation (SNARE) Fingerprinting using Deep Learning to identify UAVs}, 
  year={2022},
  volume={},
  number={},
  pages={1-12},
  abstract={Currently, there are emerging challenges with non-cooperative unmanned aerial vehicle (UAV) operating in urban airspaces. Likewise, law-enforcement groups need UAV detection capabilities to respond for safety and security (e.g., as defined for situation awareness at airports and forest fires where protocols restrict UAVs from operating within a few nautical miles from the event). This paper presents a novel physical layer authentication solution to identify UAVs that have identical visual signatures such as the same drone type and manufacturer. Within each UAV, the radio frequency (RF) signals transmitted from UAVs have a unique signature, called RF fingerprint, that can be used to distinguish among UAVs. The proposed Signal-to-Noise Ratio (SNR) of the transmitted signal in the wireless domain knowledge signifies the equipment onboard the UAV. The SNR-Aware RF Exploitation (SNARE) method solution improves the overall performance of conventional machine learning neural network models applied to imagery. This paper compares the performance metrics of different deep learning techniques including convolutional neural network (CNN), deep neural network (DNN), recurrent neural network (RNN), and the effect of related hyper parameters such as size of sliding window, learning rate, and SNR range. Experimental RF data collected from multiple identical UAVs hovering in different ranges from the receiver node are employed in this study. Compared to the traditional models that do not consider the received RF signal related SNR information, our proposed SNARE improves UAV classification of the CNN, DNN, and RNN models from 84% to 96%, 91% to 96%, and 80% to 86%, respectively.},
  keywords={Radio frequency;Deep learning;Training;RF signals;Fingerprint recognition;Autonomous aerial vehicles;Data models},
  doi={10.1109/AERO53065.2022.9843479},
  ISSN={1095-323X},
  month={March},}@INPROCEEDINGS{10569242,
  author={Ochieng, Billy and Onyango, Frankline and Kuria, Peter and Wanjiru, Maryann and Maake, Benard and Awuor, Mzee},
  booktitle={2024 IST-Africa Conference (IST-Africa)}, 
  title={AI-Driven Carbon Emissions Tracking and Mitigation Model}, 
  year={2024},
  volume={},
  number={},
  pages={1-8},
  abstract={Climate change has become an urgent and all-encompassing concern, demanding an immediate and thorough response. In climate change mitigation, innovations and technological developments play a pivotal role in supporting sustainable practices. However, there is a scarcity of artificial intelligence innovations capable of integrating multiple mitigation strategies into a comprehensive model for tracking, educating, and mitigating climate change. This paper introduces a state-of-the-art AI-driven Carbon Emission Tracking and Mitigation Model which encompasses forecasting emissions based on user prompts, presenting descriptive scenarios to explain various climate change situations, and recommending mitigation strategies through Artificial Intelligence Large Language Models (LLMs). The model facilitates trace surveillance through drones and sensors, ensuring a thorough monitoring of emissions with real-time reporting to relevant authorities. This artificial intelligence model employs a machine learning algorithm that relies on the ARIMA model for forecasting, achieving an impressive accuracy rate of 97%. Finally, a system prototype was development serving as a tangible proof of concept for the proposed ideas contributing to a more sustainable world.},
  keywords={Climate change;Technological innovation;Analytical models;Time series analysis;Government;Carbon dioxide;Predictive models;Global warming;Climate change;Carbon Emissions;Carbon Footprint;Predictive Model;Large Language Models},
  doi={10.23919/IST-Africa63983.2024.10569242},
  ISSN={2576-8581},
  month={May},}@INPROCEEDINGS{9299566,
  author={Georgiev, Georgi Dimitrov and Hristov, Georgi and Zahariev, Plamen and Kinaneva, Diyana},
  booktitle={2020 28th National Conference with International Participation (TELECOM)}, 
  title={Forest Monitoring System for Early Fire Detection Based on Convolutional Neural Network and UAV imagery}, 
  year={2020},
  volume={},
  number={},
  pages={57-60},
  abstract={Forest fires are one of the main reasons for environmental degradation. In their early stages, the fires are hard to discover, so a faster and more accurate detection method can help minimize the amount of damage they can inflict. In this paper, we present an approach for autonomous early fire detection, which is based on a system with high degree of reliability and with no need of service or human interaction. To provide the autonomous capabilities to the proposed system, we have developed an object detection method, based on a convolutional neural network, which is presented in the main part of the paper. In order to have a better field of view over the observed area, instead of traditional lookout towers and satellite based monitoring, we use live video feed from an unmanned aerial vehicle (UAV), which patrols over the risky area. To make better predictions on the fire probability, we use not only the optical camera of the UAV, but also an on-board thermal camera. With the help of the software platform Node-RED, we have developed a web-based platform, which can present the acquired data in real-time and can notify the interested parties. The workflow for the development of the web-platform is also described in this paper.},
  keywords={Cameras;Fires;Drones;Forestry;Servers;Object detection;Global Positioning System;deep learning;forest fires;neural network;object detection},
  doi={10.1109/TELECOM50385.2020.9299566},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{10286938,
  author={Heracleous, Constantinos and Kolios, Panayiotis and Panayiotou, Christos},
  booktitle={2023 International Conference on Information and Communication Technologies for Disaster Management (ICT-DM)}, 
  title={Multi-UAV Wildfire Perimeter Monitoring System}, 
  year={2023},
  volume={},
  number={},
  pages={1-8},
  abstract={Monitoring the perimeter of a wildfire in real time is crucial for effective firefighting and decision-making. This paper proposes a multi-UAV system that combines real-time infield data with a fire propagation model to accurately predict the state of the wildfire perimeter and improve fire prediction. To achieve this, a data fusion scheme is used to merge historical data with real-time measurements obtained from UAVs to update the fire propagation model. The model is then used to predict the future perimeter of the fire, which then guides the team of UAVs to track the perimeter more accurately. The system has been tested through simulation experiments, indicating its effectiveness in providing accurate real-time wildfire perimeter propagation information.},
  keywords={Decision making;Data integration;Disaster management;Predictive models;Real-time systems;Data models;Information and communication technology;Autonomous aerial vehicles;drones;fires;path planning;real-time systems;remote monitoring},
  doi={10.1109/ICT-DM58371.2023.10286938},
  ISSN={2643-6868},
  month={Sep.},}@INPROCEEDINGS{10296991,
  author={Abid, Sheikh Kamran and Chan, Shiau Wei and Sulaiman, Noralfishah and Bhatti, Uzair and Nazir, Umber},
  booktitle={2023 International Conference on Engineering Management of Communication and Technology (EMCTECH)}, 
  title={Present and Future of Artificial Intelligence in Disaster Management}, 
  year={2023},
  volume={},
  number={},
  pages={1-7},
  abstract={In the field of disaster management, it is imperative to recognize the progress made in the study of natural disasters, particularly in terms of methodology and technology. Artificial intelligence is being utilized in various fields and industries. The field of study includes various disciplines such as geospatial analysis, robotics, technology for drones, machine learning, telecommunications and network services, remote sensing, and environmental impact assessment. The incorporation of technology across various sectors is essential for accelerating societal change. Recent technological advancements have greatly influenced studying societal responses to risks and catastrophes. Researchers in the social sciences have utilized various methodologies and approaches to study natural disasters from the viewpoints of their specific disciplines, as well as transdisciplinary and interdisciplinary domains. The researchers used quantitative and qualitative methodologies for data collection and analysis. This study provides a comprehensive analysis of the various applications of AI currently utilized throughout different stages of disaster management. The statement above highlights the substantial influence of AI in different fields, emphasizing its ability to provide quick and efficient responses characterized by increased speed, precision, and readiness. Utilizing remote sensing and geographic information systems in disaster management improves planning and analysis capabilities, facilitates situational awareness, and accelerates recovery efforts. There is a widely accepted agreement among individuals regarding the significant importance of GIS and RS in managing emergencies. In mitigating the impacts of natural disasters, governmental entities can enhance the efficiency of decision-Making by employing visualization tools, satellite imagery, and AI analyses.},
  keywords={Service robots;Social sciences;Disaster management;Spatial databases;Geospatial analysis;Telecommunications;Sensors;artificial intelligence;disaster management;remote sensing;geographic information system},
  doi={10.1109/EMCTECH58502.2023.10296991},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{10073774,
  author={Saravanan, S.K. and Krishna Kumar, TP and Udaya Suriya Rajkumar, D. and Krishnamoorthy, R. and Narayana Rao, R. and Thiagarajan, R.},
  booktitle={2023 Third International Conference on Artificial Intelligence and Smart Energy (ICAIS)}, 
  title={IoT Alert Reflexion of Forbidden Deforestation Regions with Drone observation}, 
  year={2023},
  volume={},
  number={},
  pages={1650-1655},
  abstract={This article proposes a novel technique to assist the management or an authorized individual to identify the location of the deforestation activities such as tree-cutting, fires, or the intense heat in the forest via GPS, as it is now becoming difficult to stop illegal tree trafficking. IoT can help bots in the establishment of effective forest management and surveillance. The collection and utilization of basic forestry data poses a number of challenges for emerging economies. Data on daily forestry, burned zone evaluation, and forest infraction monitoring can help those in charge of maintaining forests and respond more effectively and make better decisions.},
  keywords={Heating systems;Surveillance;Forestry;Vegetation;Feature extraction;Sensors;Planning;IoT;Drones;Remote Sensing;GPS;Deforestation},
  doi={10.1109/ICAIS56108.2023.10073774},
  ISSN={},
  month={Feb},}@INPROCEEDINGS{10499574,
  author={Gao, Xiaochen and Bai, Xiangyu and Zhou, Kexin},
  booktitle={2023 International Conference on High Performance Big Data and Intelligent Systems (HDIS)}, 
  title={Research on the Application of Drone Remote Sensing and Target Detection in Civilian Fields}, 
  year={2023},
  volume={},
  number={},
  pages={108-112},
  abstract={Unmanned aerial vehicle (UAV) remote sensing has evolved as an efficient means of geospatial data acquisition. This paper provides a comprehensive review of the key technologies enabling intelligent analysis of UAV remote sensing images, specifically payload technology and object detection algorithms. Main payload systems including optical, multispectral, hyper-spectral, SAR, and LiDAR are introduced, with analyses of their working principles, performance benchmarks, and suitable application scenarios. In terms of object detection, traditional methods and emerging deep learning-based techniques are discussed and compared. The superior capabilities of anchor-free and Transformer-based detectors are analyzed through representative algorithms like CenterNet, FCOS, and DETR. Additionally, case studies demonstrate the broad applications and profound value of UAV remote sensing with intelligent target detection in areas such as precision agriculture, environmental conservation, infrastructure monitoring, and emergency response. Overall, this paper offers an in-depth examination of the landscape and trends of core technologies augmenting UAV remote sensing, providing guidance for future research and applications.},
  keywords={Reviews;Object detection;Optical detectors;Autonomous aerial vehicles;Transformers;Optical imaging;Market research;Civil UAVs;Remote sensing technology;Payloads;Deep learning;Object detection},
  doi={10.1109/HDIS60872.2023.10499574},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{10276328,
  author={Krishna, T V Sai and Bhargavi, V and Jyothsna, S and Rakesh, Vuduga and Bikshapathi, Dadi and Saritha, D},
  booktitle={2023 4th International Conference on Smart Electronics and Communication (ICOSEC)}, 
  title={Leveraging Radial Basis Function Neural Networks with Adaptive Variability Functionality to Predict Wild Fires}, 
  year={2023},
  volume={},
  number={},
  pages={1583-1588},
  abstract={A forest fire is a risk to the environment that has an impact on both human and animal life. So it's crucial to forecast forest fires. Nowadays, a lot of methods for predicting forest fires are based on Machine Learning (ML) and Deep Learning (DL) algorithms. By delivering solutions to numerous crises, like forest fires, ML is assisting the planet. In this work, a Radial Basis Function Neural Network with Adaptive Variability Functionality (RBFNN-AVF) was proposed. To anticipate forest fires in images, the ML method RBFNN-AVF is used in this work. Building a model for early wildfire identification and aiding in damage management due to such occurrences are the goals of employing such a system. There are several approaches to finding forest fires, including sensor detection and real-time geological data processing. However, utilizing picture classification, where ML is the most efficient method, is one of the greatest techniques to detect fire. ML techniques allow for the addition of these response systems or the configuration of drones with them, allowing for the frequent taking of pictures from the sky, the detection of smoke in dense forests, and the prompt notification of the appropriate authorities. Using the RBFNN-AVF approach, \ fire detection is carried out using the suggested model, and the results were successful in terms of accuracy. Therefore, using a model based on ML to handle calamitous scenarios may be an option. Out of all of these classification models, RBFNN-AVF had the highest precision of 96.9%. According to the results, it is possible to predict a wildfire's size before it even starts by analyzing climate data.},
  keywords={Adaptation models;Adaptive systems;Planets;Biological system modeling;Weather forecasting;Forestry;Radial basis function networks;Classification;Climatic Changes;Severe Heat Waves;Forest fires;Wildfires;Wind Pattern},
  doi={10.1109/ICOSEC58147.2023.10276328},
  ISSN={},
  month={Sep.},}@ARTICLE{9839647,
  author={Fouda, Mostafa M. and Sakib, Sadman and Fadlullah, Zubair Md and Nasser, Nidal and Guizani, Mohsen},
  journal={IEEE Network}, 
  title={A Lightweight Hierarchical AI Model for UAV-Enabled Edge Computing with Forest-Fire Detection Use-Case}, 
  year={2022},
  volume={36},
  number={6},
  pages={38-45},
  abstract={As the unmanned aerial vehicles (UAVs) continue to be deployed for various mission-critical data acquisition, localized computing on the drone-acquired data for efficient analysis, without significantly impacting the limited resources on board the drone, has emerged as a formidable research challenge. In this article, we address this issue with a natural resource management use-case whereby early forest-fire detection using the popular convolutional neural network (CNN)-based inference models are considered in the drone. This can lead to resource exhaustion. To alleviate this, we propose a lightweight hierarchical artificial intelligence (AI) framework, which adaptively switches between a simple machine learning-based model and an advanced deep learning-based CNN model. Then, we formulate a multi-objective optimization problem to model the trade-off between forest-fire detection accuracy and computational performance. We obtain the Pareto-optimal solution of the formulated problem by optimizing a new hyperparameter (i.e., the confidence score threshold) by employing the technique for order of preference by similarity to ideal solution (TOPSIS) for the whole model. Thus, we alleviate the computational burden while retaining a high level of detection accuracy. Finally, based on a real dataset, empirical results are reported to evaluate the performance of our proposal in terms of its lightweight features.},
  keywords={Computational modeling;Artificial intelligence;Edge computing;Drones;Forestry;Adaptation models;Autonomous aerial vehicles;Data acquisition;Mission critical systems},
  doi={10.1109/MNET.003.2100325},
  ISSN={1558-156X},
  month={November},}@INPROCEEDINGS{9690074,
  author={Liu, Bingqian and Huang, Jianye and Lin, Shuang and Yang, Yan and Qi, Yincheng},
  booktitle={2021 IEEE 3rd International Conference on Power Data Science (ICPDS)}, 
  title={Improved YOLOX-S Abnormal Condition Detection for Power Transmission Line Corridors}, 
  year={2021},
  volume={},
  number={},
  pages={13-16},
  abstract={In transmission line corridors, there are numerous abnormal conditions, such as bird nests, suspended foreign objects, wildfires, and smog, which always affect the normal operation of transmission systems. Considering the various types of foreign objects, complex backgrounds, occlusion, wildfires, irregular smoke shapes, and the real-time requirements of drone detection, this paper introduces an information aggregation algorithm based on YOLOX-S. This algorithm enhances relevant features and suppresses irrelevant features by aggregating spatial information and channel information in the feature map, which raises the overall learning ability of the network to improve the detection accuracy. Finally, the test on the transmission line environmental data set shows that the detection accuracy of this method in abnormal conditions such as bird's nest, hanging foreign body, wildfire and smog is 88.5%, which is 13.9% higher than that before the improvement, and the increase of reasoning time is very small. The experimental results show that this method has made significant progress in the abnormal environmental condition detection of power transmission line corridors.},
  keywords={Power transmission lines;Shape;Fires;Feature extraction;Birds;Real-time systems;Safety;Object Detection;Transmission Line;YOLOX-S;Information Aggregation},
  doi={10.1109/ICPDS54746.2021.9690074},
  ISSN={},
  month={Dec},}@ARTICLE{9703336,
  author={Kang, Junhyung and Tariq, Shahroz and Oh, Han and Woo, Simon S.},
  journal={IEEE Access}, 
  title={A Survey of Deep Learning-Based Object Detection Methods and Datasets for Overhead Imagery}, 
  year={2022},
  volume={10},
  number={},
  pages={20118-20134},
  abstract={Significant advancements and progress made in recent computer vision research enable more effective processing of various objects in high-resolution overhead imagery obtained by various sources from drones, airplanes, and satellites. In particular, overhead images combined with computer vision allow many real-world uses for economic, commercial, and humanitarian purposes, including assessing economic impact from access crop yields, financial supply chain prediction for company’s revenue management, and rapid disaster surveillance system (wildfire alarms, rising sea levels, weather forecast). Likewise, object detection in overhead images provides insight for use in many real-world applications yet is still challenging because of substantial image volumes, inconsistent image resolution, small-sized objects, highly complex backgrounds, and nonuniform object classes. Although extensive studies in deep learning-based object detection have achieved remarkable performance and success, they are still ineffective yielding a low detection performance, due to the underlying difficulties in overhead images. Thus, high-performing object detection in overhead images is an active research field to overcome such difficulties. This survey paper provides a comprehensive overview and comparative reviews on the most up-to-date deep learning-based object detection in overhead images. Especially, our work can shed light on capturing the most recent advancements of object detection methods in overhead images and the introduction of overhead datasets that have not been comprehensively surveyed before.},
  keywords={Object detection;Head;Detectors;Transformers;Satellites;Feature extraction;Remote sensing;Object detection;satellites;synthetic aperture radar;unmanned aerial vehicles},
  doi={10.1109/ACCESS.2022.3149052},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{9914480,
  author={Li, Binhao and Zhong, Jingwen and Shi, Guoliang and Fang, Jie},
  booktitle={2022 9th International Conference on Dependable Systems and Their Applications (DSA)}, 
  title={Forest Fire Spread Prediction Method based on BP Neural Network}, 
  year={2022},
  volume={},
  number={},
  pages={954-959},
  abstract={This paper proposes a method suitable for edge computing to use neural networks to predict the spread of forest fires, aiming to improve the accuracy and efficiency of fire spread prediction, and to achieve edge computing on the drone side with low energy consumption requirements. The BP neural network model is trained by the simulated fire spread raster data obtained by FlamMap, the direction and speed of fire spread are predicted respectively, and according to the Huygens' principle, the vector fire line is obtained by the prediction data fit, and the fire line obtained by FlamMap is compared to verify the accuracy of the method. It can be considered that the same effect can be trained and calculated for the spread of fire through remote sensing data of real fires.},
  keywords={Uncertainty;Neural networks;Forestry;Predictive models;Data models;Behavioral sciences;Fuels;Forest fire spread;BP neural network;Huygens' principle},
  doi={10.1109/DSA56465.2022.00134},
  ISSN={2767-6684},
  month={Aug},}@INPROCEEDINGS{10067042,
  author={Kacker, Tanmay and Perrusquia, Adolfo and Guo, Weisi},
  booktitle={2023 International Conference on Artificial Intelligence in Information and Communication (ICAIIC)}, 
  title={Multi-Spectral Fusion using Generative Adversarial Networks for UAV Detection of Wild Fires}, 
  year={2023},
  volume={},
  number={},
  pages={182-187},
  abstract={Wild fires are now increasingly responsible for immense ecological damage. Unmanned aerials vehicles (UAVs) are being used for monitoring and early-detection of wild fires. Recently, significant research has been conducted for using Deep Learning (DL) vision models for fire and smoke segmentation. Such models predominantly use images from the visible spectrum, which are operationally prone to large false-positive rates and sub-optimal performance across environmental conditions. In comparison, fire detection using infrared (IR) images has shown to be robust to lighting and environmental variations, but long range IR sensors remain expensive. There is an increasing interest in the fusion of visible and IR images since a fused representation would combine the visual as well as thermal information of the image. This yields significant benefits especially towards reducing false positive scenarios and increasing robustness of the model. However, the impact of fusion of the two spectrum on the performance of fire segmentation has not been extensively investigated. In this paper, we assess multiple image fusion techniques and evaluate the performance of a U-Net based segmentation model on each of the three image representations - visible, IR and fused. We also identify subsets of fire classes that are observed to have better results using the fused representation.},
  keywords={Image segmentation;Visualization;Biological system modeling;Fires;Lighting;Infrared image sensors;Image representation;fire detection;deep learning;UAV;drone;GAN},
  doi={10.1109/ICAIIC57133.2023.10067042},
  ISSN={2831-6983},
  month={Feb},}@ARTICLE{7807176,
  author={Erdelj, Milan and Natalizio, Enrico and Chowdhury, Kaushik R. and Akyildiz, Ian F.},
  journal={IEEE Pervasive Computing}, 
  title={Help from the Sky: Leveraging UAVs for Disaster Management}, 
  year={2017},
  volume={16},
  number={1},
  pages={24-32},
  abstract={This article presents a vision for future unmanned aerial vehicles (UAV)-assisted disaster management, considering the holistic functions of disaster prediction, assessment, and response. Here, UAVs not only survey the affected area but also assist in establishing vital wireless communication links between the survivors and nearest available cellular infrastructure. A perspective of different classes of geophysical, climate-induced, and meteorological disasters based on the extent of interaction between the UAV and terrestrially deployed wireless sensors is presented in this work, with suitable network architectures designed for each of these cases. The authors outline unique research challenges and possible solutions for maintaining connected aerial meshes for handoff between UAVs and for systems-specific, security- and energy-related issues. This article is part of a special issue on drones.},
  keywords={Wireless sensor networks;Robot sensing systems;Monitoring;Disaster management;Drones;Terrain factors;Unmanned aerial vehicles;Mobile robots;Big data;Internet;unmanned aerial vehicles;UAVs;wireless sensor networks;disaster management;drones;mobile;pervasive computing;disaster management;robotics;distributed systems;big data;Internet/Web technologies;networking;first response},
  doi={10.1109/MPRV.2017.11},
  ISSN={1558-2590},
  month={Jan},}@INPROCEEDINGS{8705853,
  author={Liu, Kaikai and Chauhan, Shivam and Devaraj, Revathy and Shahi, Sneha and Sreekumar, Unnikrishnan},
  booktitle={2019 IEEE International Conference on Service-Oriented System Engineering (SOSE)}, 
  title={Enabling Autonomous Unmanned Aerial Systems via Edge Computing}, 
  year={2019},
  volume={},
  number={},
  pages={374-3745},
  abstract={Unmanned Aerial Systems (UASs) have continuously demonstrated incredible value assisting with disasters such as wildfires and hurricanes. For example, UASs can help reduce risk in firefighting and increase useful data that can aid in developing a more informed strategy. Yet, performing tasks safely through tight spaces and accurately detecting nearby objects remains a major challenge facing fully autonomous flying. Due to the safety concern, CAL Fire has resisted the use of fire service UASs due to the unreliability of collision avoidance. Realizing the full potential of UASs for assisting with disasters will call for autonomous UASs that must be autonomous, taskable, and adaptive to incident situations, and respect safety, privacy, and regulatory concerns. In this paper, we propose the development of autonomous UASs capable of autonomous navigation, localization, 3-D mapping, and achieve on-board data processing and decision making. The UAS will fly and make decision using only on-board sensors and processors. Our contribution covers hardware design and embedded programming to multi-modal sensing, vision-based navigation, and hybrid mapping. We developed a new edge computing and sensing system for UASs which is compatible with existing open source autopilot software and deep-learning frameworks. We proposed a multi-modal sensing based hybrid localization and obstacle detection approach that runs in real time on board. The output of the localization and obstacle detection results is fused with high-level understanding and is used to control the UASs locally without rely on the link to a ground station. Our evaluation results demonstrate an autonomous UAS flying based on pre-defined destinations with on-board deep learning for perception and obstacle avoidance.},
  keywords={Drones;Cameras;Navigation;Sensors;Edge computing;Software;Hardware;autonomous drones;unmanned aerial vehicle;multi-sensor perception},
  doi={10.1109/SOSE.2019.00063},
  ISSN={2642-6587},
  month={April},}@INPROCEEDINGS{10112804,
  author={A, Krishnaveni and M, Harsha H and Reddy, J Vishnu and Praveen, K and Mulumudi, Adarsh Reddy},
  booktitle={2023 9th International Conference on Advanced Computing and Communication Systems (ICACCS)}, 
  title={IoT and AI based Forest Fire Prediction and Animal Monitoring System}, 
  year={2023},
  volume={1},
  number={},
  pages={1590-1594},
  abstract={Forest fires, caused by high air temperatures, are a common occurrence during the summer months in areas with Mediterranean climates, including Turkey. The country’s constitution requires the reforestation of fire-affected zones, which can be achieved using remote sensing techniques for identification and rehabilitation. Regarding animal health, current methods for monitoring require assessments and diagnoses from veterinary professionals, leading to delayed treatment and a decline in health. To address this issue, we propose a system that tracks animal health and enables primary diagnosis by the animal’s owner. The system includes sensors for blood pressure, ECG, temperature, heart rate, and breathing rate, installed on the animal’s body to collect physiological data. Furthermore, the spread of crop destruction by dangerous wild animals has become a societal issue, impacting communities and regions, and causing problems such as roadkill and village appearance. Therefore, it is crucial to develop a plan for reducing the number of dangerous animals and maintaining a healthy population. This can be achieved through big data analysis algorithms for dangerous animals, real-time wired/wireless data processing, and performance monitoring research, resulting in an IoT and AI-based intelligent system for harmful wild animal extermination that can be applied in farmhouses, orchards, airports, and military boundaries.},
  keywords={Temperature sensors;Temperature distribution;Animals;Sociology;Forestry;Real-time systems;Software;Forest Fire;Sensors;AI;Heart Rate;Animal Monitor},
  doi={10.1109/ICACCS57279.2023.10112804},
  ISSN={2575-7288},
  month={March},}@INPROCEEDINGS{9476800,
  author={Balcerzak, A. Tomasz and Jasiuk, B. Ewa and Fellner, C. Andrzej and Feltynowski, D. Mariusz},
  booktitle={2021 International Conference on Unmanned Aircraft Systems (ICUAS)}, 
  title={The Polish perspective of using unmanned aerial vehicle systems in international firefighting and crisis management missions - legal and technological analysis}, 
  year={2021},
  volume={},
  number={},
  pages={1478-1487},
  abstract={The subject of using UAV (Unmanned Aerial Vehicle) in extinguishing activities during large-scale forest fires is described in the scientific literature. For example, the Web of Science service for the period 1990-2018 recorded 308 publications related to UAV and forest fires [1]. These are mainly analyzes and studies on remote fire detection, monitoring, mapping, architecture and technology integration. There is a noticeable growing interest of researchers in the subject of using machine learning to detect and predict the spread of fires using unmanned aerial vehicles [2]. At the same time, analyzes are carried out on the ad-hoc creation of local data networks using drones [3], or drones as an element of the Internet of Things (IoT) [4]. In the operational context, concepts and solutions such as water transfer and extinguishing with UAV are only being tested. [5]. Another important challenge is that current firefighting civil aviation regulations only allow firefighting manned aircrafts to operate between first and last flight due to safety concerns for pilots, limiting the operation time to an average of 12 hours, which leads to many fires reactivating at night. This paper will analyze the legal and technological polish perspective of Unmanned Aircraft Systems usage in international firefighting and crisis management missions.},
  keywords={Industries;Crisis management;Law;Europe;Organizations;Forestry;Streaming media},
  doi={10.1109/ICUAS51884.2021.9476800},
  ISSN={2575-7296},
  month={June},}@ARTICLE{10633236,
  author={Rajoli, Hossein and Khoshdel, Sahand and Afghah, Fatemeh and Ma, Xiaolong},
  journal={IEEE Transactions on Geoscience and Remote Sensing}, 
  title={FlameFinder: Illuminating Obscured Fire Through Smoke With Attentive Deep Metric Learning}, 
  year={2024},
  volume={62},
  number={},
  pages={1-12},
  abstract={FlameFinder, a novel deep metric learning (DML) framework, accurately detects RGB-obscured flames using thermal images from firefighter drones during wildfire monitoring. In contrast to RGB, thermal cameras can capture smoke-obscured flame features but they lack absolute thermal reference points, detecting many nonflame hot spots as false positives. This issue suggests that extracting features from both modalities in unobscured cases can reduce the model’s bias to relative thermal gradients. Following this idea, our proposed model utilizes paired thermal-RGB images captured onboard drones for training, learning latent flame features from smoke-free samples. In testing, it identifies flames in smoky patches based on their equivalent thermal-domain distribution, improving performance with supervised and distance-based clustering metrics. The approach includes a flame segmentation method and a DML-aided detection framework with center loss (CL), triplet CL (TCL), and triplet cosine CL (TCCL), to find the optimal cluster representatives for classification. Evaluation of FLAME2 and FLAME3 datasets shows the method’s effectiveness in diverse fire and no-fire scenarios. However, the CL dominates the two other losses, resulting in the model missing features that are sensitive to them. To overcome this issue, an attention mechanism is proposed making nonuniform feature contribution possible and amplifying the critical role of cosine and triplet loss in the DML framework. Plus, the attentive DML shows improved interpretability, class discrimination, and decreased intraclass variance exploiting several other flame-related features. The proposed model surpasses the baseline with a binary classifier by 4.4% in FLAME2 and 7% in FLAME3 datasets for unobscured flame detection accuracy. It also demonstrates enhanced class separation in obscured scenarios compared to fine-tuned VGG19, ResNet18, and three other backbone models tailored for flame detection.},
  keywords={Feature extraction;Wildfires;Measurement;Training;Image segmentation;Attention mechanisms;Monitoring;Attention;deep metric learning;flame detection},
  doi={10.1109/TGRS.2024.3440880},
  ISSN={1558-0644},
  month={},}@INPROCEEDINGS{9685547,
  author={Lewicki, Tomasz and Liu, Kaikai},
  booktitle={2021 IEEE Global Communications Conference (GLOBECOM)}, 
  title={Multimodal Wildfire Surveillance with UAV}, 
  year={2021},
  volume={},
  number={},
  pages={1-6},
  abstract={Wildfires are a growing problem in the US and worldwide. In the last decade, we witnessed some of the costliest, most destructive, and deadliest wildland fires on record. This project proposes a vision-based multimodal fire detection system on an Unmanned Aerial Vehicle (UAV, drone) that can be used for early detection of new wildfires, and surveillance of existing ones. In this paper, we present a vision-based aerial sensing system with an onboard intelligent processor and precise fire sensing systems. We create a new open-source UAV system for joint autopiloting and multi-sensory object localization and detection with a tight power budget. We designed a Fire Perception Box multimodal perception hardware that can be installed on our UAV system. To improve the fire scene detection robustness and accuracy, we propose to perform the fusion of Visual spectrum (RGB) and infrared (IR) sensors with an onboard deep learning-based algorithm. Overall, our proposed system is capable of fully onboard real-time visual processing and produces spatial results which can later be utilized to generate the needed real-time wildfire maps. The effectiveness of the system evaluated based on our own collected Aerial Fire Dataset in a real fire training scenario (80-acre wildfire) in Sacramento, California, as well as other existing fire-related datasets. Some part of our solutions are open-sourced via Github [1] and [2].},
  keywords={Training;Visualization;Surveillance;Fires;Sensor fusion;Autonomous aerial vehicles;Real-time systems;Autonomous UAV;object detection;localization},
  doi={10.1109/GLOBECOM46510.2021.9685547},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{10696597,
  author={Manikandan, N K and Muktha, Chaturya and Abhinai, Yegi and Manivannan, D},
  booktitle={2024 Second International Conference on Intelligent Cyber Physical Systems and Internet of Things (ICoICI)}, 
  title={Forest Monitoring and Protection Using Motion Sensors and Metal Detection}, 
  year={2024},
  volume={},
  number={},
  pages={1541-1546},
  abstract={This research explores the implementation of advanced monitoring and protection systems to safeguard forests from illegal activities. By leveraging devices, remote sensing, and drones equipped with high-resolution cameras, these systems enable real-time surveillance and data analysis. Artificial intelligence is employed to detect suspicious activities, triggering alerts to forest rangers and conservation authorities. Community engagement and education programs are integrated to foster sustainable practices among local populations. This combined approach aims to preserve biodiversity, combat climate change, and ensure the long-term health of forest habitats. The proposed system, combining motion and metal detection, provides a comprehensive solution for monitoring high-risk areas. By detecting suspicious activities and sending immediate alerts, this system enhances vigilance and discourages illegal activities, ultimately contributing to the preservation of forests.},
  keywords={Wireless sensor networks;Climate change;Technological innovation;Forests;Data analysis;Metals;Real-time systems;Biodiversity;Protection;Remote sensing;wireless sensor networks (WSNs);Light Detection and Ranging (LiDAR);Conference on Computer Vision and Pattern Recognition (CVPR)},
  doi={10.1109/ICoICI62503.2024.10696597},
  ISSN={},
  month={Aug},}@INPROCEEDINGS{8068417,
  author={Divya, K. Veena and Swetha, R. R. and Rajasree, P.M. and Vidya, M.J. and Burahman, Azka Muji},
  booktitle={2017 5th International Conference on Instrumentation, Control, and Automation (ICA)}, 
  title={Airborne parameter instrumentation system for disaster supervision in smart cities-a prototype}, 
  year={2017},
  volume={},
  number={},
  pages={78-81},
  abstract={For environmental impact analysis remote hosting of instrumentation system consisting of sensors provides a seamless, authentic method of establishing communication. These methods provide the on the spot parametric measures for prediction analysis and disaster management. Though the drones provide visual imagery of the impacted area, they are faced with payload and power limitations when sensors are to be mounted. This paper discusses an airborne remote instrumentation system (APIS) of using High-altitude balloons (HAB) with sensors. These are unmanned balloons, filled with either hydrogen or helium, released from ground and travel up to the stratosphere. Due to their comparatively low rate-of-ascent, these balloons are perfect choices for precise measurements of sections of the atmosphere. A distress signal is sent to rescue centers and ground stations to receive help. Data from the disaster struck area is collected and sent for analysis. The main objective of this system is to provide smart communication enabling speedy rescue mission along with humidity levels and temperature data in case of forest fires.},
  keywords={Payloads;Sensors;Microcontrollers;ZigBee;Meters;Hardware;Airborne Parameter Instrumentation System;Disaster management system;Balloon based monitoring},
  doi={10.1109/ICA.2017.8068417},
  ISSN={},
  month={Aug},}
